{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab6.3-Topic-modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to build a topic model using Latent Dirichlet Allocation using the Sklearn package.\n",
    "\n",
    "Credits: This notebook is an adaptation of the work of Shashank Kapadia:\n",
    "\n",
    "https://github.com/kapadias/mediumposts/blob/master/nlp/published_notebooks/\n",
    "\n",
    "The dataset can be found here: https://www.kaggle.com/benhamner/nips-papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "\n",
    "# Read data into papers\n",
    "papers = pd.read_csv('papers.csv')\n",
    "\n",
    "# Print head\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning\n",
    "\n",
    "Since the goal of this analysis is to perform topic modeling, we will solely focus on the text data from each paper, and drop other metadata columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                              title          abstract  \\\n",
       "0  1987  Self-Organization of Associative Database and ...  Abstract Missing   \n",
       "1  1987  A Mean Field Theory of Layer IV of Visual Cort...  Abstract Missing   \n",
       "2  1988  Storing Covariance by the Associative Long-Ter...  Abstract Missing   \n",
       "3  1994  Bayesian Query Construction for Neural Network...  Abstract Missing   \n",
       "4  1994  Neural Network Ensembles, Cross Validation, an...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the columns\n",
    "papers = papers.drop(columns=['id', 'event_type', 'pdf_name'], axis=1)\n",
    "\n",
    "# Print out the first rows of papers\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove punctuation/lower casing\n",
    "\n",
    "Next, let’s perform a simple preprocessing on the content of paper_text column to make them more amenable for analysis, and reliable results. To do that, we’ll use a regular expression to remove any punctuation, and then lowercase the text. Note that we care less about the linguistic notion of words and sentences since we treat the text as a basic bag-of-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    767\\n\\nself-organization of associative databa...\n",
       "1    683\\n\\na mean field theory of layer iv of visu...\n",
       "2    394\\n\\nstoring covariance by the associative\\n...\n",
       "3    bayesian query construction for neural\\nnetwor...\n",
       "4    neural network ensembles cross\\nvalidation and...\n",
       "Name: paper_text_processed, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the regular expression library\n",
    "import re\n",
    "\n",
    "# Remove punctuation\n",
    "papers['paper_text_processed'] = papers['paper_text'].map(lambda x: re.sub(r'[,\\.!?]', '', x))\n",
    "\n",
    "# Convert the titles to lowercase\n",
    "papers['paper_text_processed'] = papers['paper_text_processed'].map(lambda x: x.lower())\n",
    "\n",
    "# Print out the first rows of papers\n",
    "papers['paper_text_processed'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Analysis\n",
    "\n",
    "To verify whether the preprocessing happened correctly, we’ll make a word cloud using the wordcloud package to get a visual representation of most common words. It is key to understanding the data and ensuring we are on the right track, and if any more preprocessing is necessary before training the model.\n",
    "\n",
    "You can install WordCloud from the command line following the instructions at:\n",
    "\n",
    "https://anaconda.org/conda-forge/wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Join the different processed titles together.\n",
    "long_string = ','.join(list(papers['paper_text_processed'].values))\n",
    "\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=1000, contour_width=3, contour_color='steelblue')\n",
    "\n",
    "# Generate a word cloud\n",
    "wordcloud.generate(long_string)\n",
    "\n",
    "# Visualize the word cloud\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare text for LDA analysis\n",
    "\n",
    "Next, let’s work to transform the textual data in a format that will serve as an input for training LDA model. We start by converting the documents into a simple vector representation (Bag of Words BOW). Next, we will convert a list of titles into lists of vectors, all with length equal to the vocabulary. For this we use the CountVectorizer package from sklearn and apply the *fit_transform* function to the lists of texts from our pandas frame.\n",
    "\n",
    "We’ll then plot the ten most frequent words based on the outcome of this operation (the list of document vectors). As a check, these words should also occur in the word cloud. This is done by the Helper function defined below using the matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\szcze\\AppData\\Local\\Temp\\ipykernel_6908\\2706173689.py:27: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=x_pos, y=counts, palette='husl')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x927.07 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the library with the CountVectorizer method\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper function\n",
    "def plot_10_most_common_words(count_data, count_vectorizer):\n",
    "    import matplotlib.pyplot as plt\n",
    "    words = count_vectorizer.get_feature_names_out()\n",
    "    total_counts = np.zeros(len(words))\n",
    "    for t in count_data:\n",
    "        total_counts+=t.toarray()[0]\n",
    "    \n",
    "    count_dict = (zip(words, total_counts))\n",
    "    count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:10]\n",
    "    words = [w[0] for w in count_dict]\n",
    "    counts = [w[1] for w in count_dict]\n",
    "    x_pos = np.arange(len(words)) \n",
    "    \n",
    "    plt.figure(2, figsize=(15, 15/1.6180))\n",
    "    plt.subplot(title='10 most common words')\n",
    "    sns.set_context(\"notebook\", font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n",
    "    sns.barplot(x=x_pos, y=counts, palette='husl')\n",
    "    plt.xticks(x_pos, words, rotation=90) \n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('counts')\n",
    "    plt.show()\n",
    "\n",
    "# Initialise the count vectorizer with the English stop words\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the processed titles\n",
    "count_data = count_vectorizer.fit_transform(papers['paper_text_processed'])\n",
    "\n",
    "# Visualise the 10 most common words\n",
    "plot_10_most_common_words(count_data, count_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA model tranining\n",
    "\n",
    "To keep things simple, we will only tweak the number of topic parameters: number_topics and number_words.\n",
    "\n",
    "We apply the *fit* function to our count_data.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found via LDA:\n",
      "\n",
      "Topic #0:\n",
      "learning state policy time algorithm model function action regret using\n",
      "\n",
      "Topic #1:\n",
      "network model time neural input figure neurons learning networks function\n",
      "\n",
      "Topic #2:\n",
      "data algorithm set learning model function distribution 10 using number\n",
      "\n",
      "Topic #3:\n",
      "model image training data using images models learning set features\n",
      "\n",
      "Topic #4:\n",
      "algorithm matrix problem function theorem learning 10 convex data let\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "# Load the LDA model from sk-learn\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    " \n",
    "# Helper function\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names_out()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        \n",
    "# Tweak the two parameters below (use int values below 15)\n",
    "number_topics = 5\n",
    "number_words = 10\n",
    "\n",
    "# Create and fit the LDA model\n",
    "lda = LDA(n_components=number_topics)\n",
    "lda.fit(count_data)\n",
    "\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 120549)\t1\n",
      "  (0, 163063)\t1\n",
      "  (0, 183684)\t1\n",
      "  (1, 189182)\t1\n",
      "  (1, 201629)\t1\n",
      "  (1, 268021)\t1\n",
      "  (1, 272347)\t1\n",
      "  (1, 274903)\t1\n"
     ]
    }
   ],
   "source": [
    "test_data=[\"my images are difficult to learn\", \"it takes a lot of time to train a model\"]\n",
    "transformed_test_data= count_vectorizer.transform(test_data)\n",
    "print(transformed_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0508904 , 0.05038812, 0.05051122, 0.79796472, 0.05024554],\n",
       "       [0.03447292, 0.54558867, 0.03408778, 0.35205326, 0.03379737]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.transform(transformed_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing our LDA model\n",
    "\n",
    "Now that we have a trained model let’s visualize the topics for interpretability. \n",
    "To do so, we’ll use a popular visualization package, *pyLDAvis* which is designed to help interactively with:\n",
    "\n",
    "1. Better understanding and interpreting individual topics, and\n",
    "2. Better understanding the relationships between the topics.\n",
    "\n",
    "For (1), you can manually select each topic to view its top most frequent and/or “relevant” terms, using different values of the λ parameter. This can help when you’re trying to assign a human interpretable name or “meaning” to each topic.\n",
    "For (2), exploring the Intertopic Distance Plot can help you learn about how topics relate to each other, including potential higher-level structure between groups of topics.\n",
    "\n",
    "You need to install *pyldavis* through the command line, following the instructions:\n",
    "\n",
    "https://anaconda.org/conda-forge/pyldavis\n",
    "\n",
    "WARNING: running the next cell takes a long time and you need some memory to run it. However, the result is spectacular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el690817289954083368533809608\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el690817289954083368533809608_data = {\"mdsDat\": {\"x\": [0.05300765795010954, 0.11943550436059613, -0.07119597364363417, -0.13232225989093552, 0.03107507122386412], \"y\": [-0.004342118069825575, -0.06800636137896779, 0.047022658464557936, -0.06679033107701815, 0.09211615206125358], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [30.795391852046944, 20.27080291409779, 19.024488629897924, 16.003176684477893, 13.906139919479447]}, \"tinfo\": {\"Term\": [\"image\", \"policy\", \"images\", \"network\", \"matrix\", \"neurons\", \"state\", \"neural\", \"model\", \"convex\", \"object\", \"theorem\", \"time\", \"algorithm\", \"regret\", \"input\", \"action\", \"recognition\", \"learning\", \"reward\", \"neuron\", \"norm\", \"training\", \"spike\", \"features\", \"networks\", \"gradient\", \"visual\", \"rank\", \"stimulus\", \"treewidth\", \"submodularity\", \"supermodular\", \"ddp\", \"dpp\", \"oost\", \"graphon\", \"minwise\", \"kikuchi\", \"lmnn\", \"blossom\", \"dpps\", \"ylx\", \"ocsvm\", \"hyperedge\", \"trw\", \"fci\", \"bsp\", \"lvm\", \"yeast\", \"gbs\", \"abstention\", \"anonymity\", \"mwis\", \"mplp\", \"gbp\", \"abalone\", \"ecoc\", \"multilabel\", \"spammer\", \"submodular\", \"bethe\", \"copula\", \"dags\", \"copulas\", \"mallows\", \"dcg\", \"hsic\", \"interventional\", \"marginals\", \"ising\", \"loopy\", \"mln\", \"lifted\", \"ranking\", \"graph\", \"ndcg\", \"graphs\", \"vertex\", \"hashing\", \"bic\", \"marginal\", \"partition\", \"hash\", \"clique\", \"graphical\", \"tree\", \"vertices\", \"messages\", \"clusters\", \"label\", \"pairwise\", \"bipartite\", \"clustering\", \"gibbs\", \"query\", \"edges\", \"nodes\", \"variables\", \"node\", \"cluster\", \"trees\", \"bayesian\", \"gp\", \"likelihood\", \"xi\", \"xj\", \"inference\", \"distribution\", \"data\", \"set\", \"em\", \"algorithm\", \"kernel\", \"distributions\", \"labels\", \"posterior\", \"function\", \"gaussian\", \"probability\", \"number\", \"log\", \"given\", \"model\", \"learning\", \"10\", \"models\", \"problem\", \"using\", \"based\", \"random\", \"methods\", \"algorithms\", \"method\", \"approach\", \"used\", \"results\", \"time\", \"use\", \"figure\", \"svrg\", \"sdca\", \"saga\", \"isometry\", \"nesterovs\", \"candes\", \"nnz\", \"admm\", \"tropp\", \"rpca\", \"schatten\", \"lanczos\", \"deflation\", \"agd\", \"quic\", \"svp\", \"fista\", \"teboulle\", \"prox\", \"cands\", \"knng\", \"woodruff\", \"aga\", \"kxk2\", \"ggood\", \"ogwild\", \"vershynin\", \"kzk\", \"homotopy\", \"k2f\", \"privacy\", \"incoherence\", \"donoho\", \"kxk\", \"sag\", \"nonconvex\", \"nesterov\", \"norm\", \"proximal\", \"norms\", \"rip\", \"lasso\", \"frobenius\", \"lipschitz\", \"singular\", \"tensor\", \"convex\", \"k2\", \"svd\", \"orthonormal\", \"recovery\", \"shwartz\", \"subspace\", \"k22\", \"shalev\", \"kx\", \"private\", \"rank\", \"convexity\", \"sup\", \"kf\", \"rademacher\", \"matrix\", \"eigenvalues\", \"theorem\", \"convergence\", \"rd\", \"descent\", \"sparse\", \"lemma\", \"rn\", \"matrices\", \"sparsity\", \"pca\", \"regularization\", \"proof\", \"optimization\", \"let\", \"minimization\", \"min\", \"algorithm\", \"gradient\", \"bounds\", \"problem\", \"linear\", \"analysis\", \"bound\", \"error\", \"algorithms\", \"following\", \"loss\", \"log\", \"function\", \"10\", \"case\", \"method\", \"learning\", \"methods\", \"set\", \"data\", \"functions\", \"results\", \"using\", \"number\", \"phonetic\", \"voc\", \"speakers\", \"waibel\", \"coalescent\", \"lexical\", \"pedestrian\", \"lexicon\", \"fixations\", \"vqa\", \"gsm\", \"keypoints\", \"verbs\", \"pcfg\", \"epitome\", \"mmsb\", \"gool\", \"vowels\", \"adaptor\", \"bourlard\", \"slds\", \"rcnn\", \"wordnet\", \"keypoint\", \"memorability\", \"reflectance\", \"verb\", \"voiced\", \"nouns\", \"cow\", \"images\", \"speaker\", \"scene\", \"grammar\", \"sift\", \"occlusion\", \"descriptors\", \"image\", \"phoneme\", \"hdp\", \"semantic\", \"segmentations\", \"textures\", \"torralba\", \"object\", \"word\", \"sentences\", \"saliency\", \"annotations\", \"texture\", \"grammars\", \"lighting\", \"descriptor\", \"pyramid\", \"segmentation\", \"cvpr\", \"recognition\", \"patches\", \"sentence\", \"camera\", \"pose\", \"speech\", \"3d\", \"video\", \"pixel\", \"frames\", \"pixels\", \"objects\", \"frame\", \"appearance\", \"face\", \"patch\", \"cnn\", \"language\", \"vision\", \"categories\", \"human\", \"features\", \"topic\", \"words\", \"trained\", \"training\", \"feature\", \"detection\", \"layer\", \"model\", \"representations\", \"representation\", \"models\", \"using\", \"data\", \"figure\", \"used\", \"network\", \"classification\", \"hidden\", \"set\", \"different\", \"visual\", \"learning\", \"use\", \"based\", \"results\", \"performance\", \"networks\", \"number\", \"input\", \"neural\", \"10\", \"approach\", \"information\", \"firing\", \"synaptic\", \"spiking\", \"voltage\", \"excitatory\", \"inhibitory\", \"synapses\", \"membrane\", \"synapse\", \"plasticity\", \"postsynaptic\", \"hebbian\", \"presynaptic\", \"pulse\", \"dendritic\", \"spikes\", \"stdp\", \"calcium\", \"neurosci\", \"currents\", \"electrode\", \"olfactory\", \"ganglion\", \"transistor\", \"voltages\", \"cortical\", \"lgn\", \"electrodes\", \"neurophysiol\", \"afferent\", \"spike\", \"neuron\", \"stimulus\", \"neurons\", \"chip\", \"neuronal\", \"hopfield\", \"vlsi\", \"inhibition\", \"circuit\", \"cortex\", \"eeg\", \"sensory\", \"motor\", \"auditory\", \"activity\", \"cells\", \"stimuli\", \"analog\", \"circuits\", \"cell\", \"response\", \"brain\", \"network\", \"responses\", \"input\", \"signals\", \"neural\", \"units\", \"signal\", \"time\", \"patterns\", \"dynamics\", \"output\", \"frequency\", \"inputs\", \"figure\", \"networks\", \"model\", \"fig\", \"noise\", \"information\", \"learning\", \"unit\", \"function\", \"state\", \"10\", \"weights\", \"shown\", \"different\", \"used\", \"rate\", \"using\", \"data\", \"bandits\", \"bandit\", \"gans\", \"vae\", \"auctions\", \"rollout\", \"svhn\", \"buyer\", \"seller\", \"dueling\", \"atari\", \"sghmc\", \"wierstra\", \"buyers\", \"tensorflow\", \"rezende\", \"mcts\", \"sgld\", \"rmsprop\", \"multiarmed\", \"gan\", \"rollouts\", \"bidder\", \"wgan\", \"diederik\", \"nmt\", \"copeland\", \"pixelcnn\", \"payoff\", \"investor\", \"regret\", \"player\", \"agent\", \"policy\", \"ucb\", \"rewards\", \"kingma\", \"critic\", \"players\", \"policies\", \"dqn\", \"reward\", \"agents\", \"games\", \"mdp\", \"dropout\", \"armed\", \"horizon\", \"actions\", \"game\", \"arms\", \"discriminator\", \"adversarial\", \"reinforcement\", \"action\", \"exploration\", \"planning\", \"lstm\", \"arm\", \"mdps\", \"2016\", \"state\", \"arxiv\", \"deep\", \"learning\", \"xt\", \"stochastic\", \"2015\", \"online\", \"time\", \"st\", \"value\", \"gradient\", \"et\", \"algorithm\", \"al\", \"optimal\", \"neural\", \"function\", \"model\", \"using\", \"networks\", \"distribution\", \"use\", \"training\", \"performance\", \"log\", \"10\", \"set\", \"problem\", \"based\", \"network\"], \"Freq\": [29412.0, 15330.0, 18964.0, 43823.0, 42482.0, 13343.0, 34106.0, 43922.0, 102377.0, 18047.0, 13389.0, 25167.0, 59235.0, 81163.0, 9461.0, 33842.0, 11960.0, 13985.0, 104097.0, 9122.0, 9197.0, 11992.0, 46250.0, 8067.0, 25478.0, 31646.0, 21593.0, 11780.0, 12493.0, 6543.0, 579.9859350399587, 573.9519477402272, 368.6114691597379, 271.8002172190534, 549.3474351006474, 220.4502589427557, 229.3075497563802, 174.0345171810103, 174.03406573573588, 485.6236314984683, 160.20669889684225, 149.3382496567114, 280.96995067232245, 147.36022321880282, 142.39043168262063, 334.81858920356507, 139.4227686446417, 131.55771732042635, 131.55619945378493, 252.30615811810608, 129.58568450455343, 126.62260418933712, 126.61743390048531, 122.67096771117455, 121.68556504287974, 121.68503436685089, 124.61392085585425, 118.72006607851897, 369.88888846057426, 114.76582594230197, 3890.293845583182, 821.9931155471968, 880.871756301014, 326.3964096713616, 302.4744470455786, 349.51437285216304, 204.47340556977963, 201.5674008808352, 179.22478983833193, 1853.4071794647614, 930.2737562600581, 853.2582550337, 384.30171767072704, 735.2748242385484, 3924.1924688523463, 16926.96863496012, 331.9553205888453, 6053.912562143836, 2323.818613800795, 1325.450007371641, 426.01875013912905, 4749.533389388133, 5008.001151080648, 1210.9071849444827, 1020.9290221790039, 5060.949505399952, 10236.020043436403, 2573.1577039823333, 1472.1510955590015, 5452.827153998892, 8153.7644509749425, 3516.796043520228, 947.099090846903, 10039.873009936755, 3375.3160403483735, 4118.031832103895, 4666.957525813463, 8859.467123665861, 14653.900236356518, 8645.335205523928, 6363.044553042489, 4005.99477462065, 10422.17721681075, 3941.1010007742307, 10433.008332524281, 18061.434759929598, 6078.826819714032, 12484.258431158327, 24382.231316764282, 44635.55888437491, 32889.20432861029, 5086.031658903223, 34171.62458709469, 13449.616769214348, 9267.73354769648, 6277.0953985962105, 8259.905976290462, 27610.662496526747, 13147.361822058405, 16012.93061269365, 21541.837373751066, 17643.25573652419, 19181.75654672838, 32109.103568173035, 32250.078603842296, 23547.422328682725, 19259.82335364505, 20238.662917086018, 22271.797104970112, 15813.945498225154, 12992.644391790316, 13946.756363888826, 13391.857696341023, 13592.810134577287, 12637.330115346746, 14038.949402933771, 13699.374464988652, 14391.64632511515, 12926.714929767972, 12905.7199099571, 803.5153685078169, 400.8625757754769, 398.87414479627665, 285.5320116337295, 273.6021331034981, 270.6200965519272, 287.3718232338283, 1099.907223039597, 238.80464735265332, 216.93426197819983, 208.98077476611377, 272.3178397997796, 187.0842740505624, 182.13211065280342, 180.14873758070587, 175.17620973002963, 167.22161388195508, 165.23026450460728, 428.4188718191893, 152.30986475971818, 146.3434301694577, 134.41508879165502, 134.41287105681224, 357.76600401662745, 128.44987295634945, 125.46582810202072, 121.48995862060977, 120.4956069953635, 158.02600778640993, 582.5707497328885, 2008.1264729945533, 402.6858011665634, 346.5405043449043, 612.424328033127, 251.26219630484837, 960.6900685465693, 536.8086281303813, 11220.15469841912, 2028.8175961193026, 1511.9215277340304, 377.663237655723, 4130.20476922057, 800.1777881105761, 2010.3423226593075, 2541.2468845341673, 4205.793215012564, 15388.170294106776, 5674.976975366784, 1719.1082893598816, 747.4228485751255, 3282.599786859696, 645.8421514323726, 4103.254189782429, 1012.0542212293202, 647.7309259268436, 2125.9051123531785, 1282.222332771892, 9734.911253590803, 1643.6443905252297, 2037.567762409678, 1973.0256218340419, 970.4260386030949, 27782.844674013922, 2788.8930809691124, 16593.88748894342, 10957.585958625074, 4068.753035692208, 5684.424006830725, 10614.964269438897, 7683.369649399391, 3804.996744261394, 6561.758615311618, 4069.6109086483, 3886.7401141225055, 6207.013256662595, 7437.65271677436, 12637.682364505334, 14307.015102332918, 4270.96772065935, 7226.982573309302, 27915.48220955197, 10536.08072153241, 7364.048658369339, 18639.32698428485, 14163.556711583218, 11485.669574039515, 10762.477879436226, 13270.347618576137, 12088.914068355449, 10536.663398775603, 9372.919466135842, 12925.981773783153, 17308.1146893957, 16386.406931292775, 11523.737898500196, 11944.915666028082, 16552.726705417077, 10743.306371991592, 13838.542654181689, 14879.537938632304, 9626.119958100335, 10400.62373387424, 10109.957397823211, 9874.816757278946, 476.89760674881893, 504.9190006624498, 719.690456268512, 274.1232049107562, 261.45132042408744, 254.62477781000138, 251.67871766822324, 244.87641574454688, 239.03249098032146, 220.5126430319867, 219.52863093847566, 213.6862458551807, 204.91110581220505, 196.1210874359447, 197.07450650584772, 176.63836815215194, 172.73208870173926, 165.91473821299303, 164.91632184673372, 188.149819967196, 154.1998857960406, 141.54858093354412, 184.193408314164, 135.69917143341317, 134.725826296435, 376.07302971620965, 320.7661984688164, 131.77100571740903, 193.7368657284483, 121.07522269462643, 18352.79146954171, 1711.847390359491, 3599.309774465608, 1215.7484698360477, 728.5744801394151, 611.6357027734882, 818.9477406153194, 28035.66298484916, 787.1857825099374, 808.3640642521669, 2947.125887908856, 437.68642418914163, 381.1416580128941, 462.07866896425736, 12743.808171150153, 7570.2522619163565, 1510.03239987688, 1506.867351153433, 790.1501347869985, 1383.45567343684, 556.9939559182493, 521.1272016987648, 623.8810385256277, 811.4457638496127, 4884.123405198518, 2669.292900255453, 12593.56354848258, 2429.0434495780437, 1720.219028961998, 1274.028934998129, 2341.3540271008064, 5672.756939378495, 3642.769735618927, 3234.2041860953386, 3744.387186863523, 2275.9061792744005, 3421.058761786375, 7176.369520160276, 2703.963607745743, 1615.91024728208, 3722.805282034461, 1868.819639094843, 2386.642978303933, 4346.982264615124, 5124.966368707515, 2664.254980919909, 6581.625613958324, 15606.088826333536, 4384.084586435459, 6460.270598770473, 7139.349028738548, 22191.23193093566, 12795.581379614414, 5308.500600927266, 9340.78515674696, 34706.88621592496, 5303.094895860962, 7427.641268838548, 16093.63883316771, 18614.57874490526, 21858.89434271937, 14689.111229491771, 13377.544205208862, 12604.052082563661, 8765.346867272698, 7152.322872757013, 15682.576483326942, 10777.565308037105, 6324.674335203509, 15843.758571851144, 10310.878606936925, 10056.235866300105, 10238.081312588514, 9020.696548975533, 8835.694627332348, 9800.996818479563, 8700.242034619961, 9054.102999445045, 8459.372220587982, 7838.775697436454, 7941.667453926489, 4143.365123825517, 4961.395270979827, 2111.6127415880574, 2035.8893313879723, 1793.964932425905, 1778.2296600363277, 2299.1607127014863, 1680.856738773861, 1596.297139523191, 1300.2829990159776, 1017.0598718002327, 1031.7826497071662, 824.3082689222144, 829.2173284506329, 787.9204442577918, 2932.7020913071788, 597.1357736274874, 588.2742640669974, 991.5856923973927, 693.0955754723042, 446.6663468847884, 430.93570733212727, 515.3016942915713, 404.38473929892933, 381.7651856396978, 2940.189967670484, 378.8129187426136, 375.85844091943954, 371.93073571391324, 367.9978966792115, 8046.964645726599, 9150.349404653574, 6508.4042104530245, 13166.323930095212, 2321.186013356253, 2025.930486031223, 1019.2502024381107, 1193.552369010656, 1361.7262733422424, 3248.7558782882456, 3870.3791237199475, 1491.2137525234198, 2503.27395107421, 2672.7989351225656, 1872.2324995031697, 6789.024107233226, 6138.766292619271, 3662.1128364675033, 2555.8742192656578, 1937.5425523780293, 5500.526784969833, 7365.72443742765, 4750.412283809146, 21829.022695194253, 3771.209167645876, 16701.997880823787, 4134.26176664084, 19783.26591926289, 7399.901203469028, 7083.966625074765, 20116.644954479907, 4930.649258782364, 5326.212655326738, 9603.785103755687, 4258.339571894053, 5017.72336601283, 14687.158465458582, 10799.734637829884, 20348.7002460477, 6268.630492246165, 7880.695176023789, 9348.422259352043, 12205.690890655582, 5040.653155203143, 9972.013259842115, 7737.935285994182, 9059.213406922148, 5926.539905728822, 6344.592588431327, 6993.1054472186615, 6738.493819878489, 6001.281363171761, 6644.7243555122495, 6567.248406835258, 1474.731700733809, 3206.262199229388, 586.1285200607673, 477.4771061697729, 450.291913184507, 360.0728029937589, 340.6917569300278, 380.34616636358703, 294.13082868257146, 288.3102161476205, 268.90881161837035, 261.14782149913464, 269.84569946633206, 249.50718901666036, 260.1284914712844, 277.5071056953604, 225.25480049398774, 218.4601790104261, 212.64015369878732, 200.98518113574607, 1585.3804319775913, 188.38872794720643, 185.48006704631297, 173.83949998396054, 186.39206921134192, 168.98837302519826, 159.28864994702388, 149.5861581180455, 913.8861426396032, 146.67410629401297, 9307.911134782791, 2710.907148423365, 5928.242346970224, 14846.022969188865, 1473.54191923952, 2529.188280478244, 548.9230208035203, 1019.3098132799871, 1749.4886949732336, 3701.743372208062, 408.5184805485213, 8758.482828302358, 3584.0829662364395, 2972.070628556311, 2633.7250642854474, 1750.9789819017449, 1116.5702564505816, 1433.428078604604, 6037.172534640907, 4410.022525616186, 1683.185921471643, 1005.300946365083, 2634.0975145959756, 5155.253238495759, 10015.472613857162, 3150.415611821284, 2532.7620959659976, 1868.1572518858977, 3050.3267647084076, 1389.3011517467746, 4600.106151617236, 16137.553520270432, 5538.273507220628, 5511.595959480434, 27245.092214879638, 6706.298689557182, 7055.8132912814, 4354.537793847703, 4840.453057468065, 13457.840483845164, 4521.667641906527, 8196.880063106611, 7058.502494529548, 7185.898298920467, 12793.802605852186, 6677.499620868759, 7289.054259330145, 8880.182782792432, 10535.58280637655, 11772.579059220534, 9135.459608790557, 6969.355374418499, 7217.07065863017, 6759.782683591598, 6931.384926560584, 6324.71784568548, 6435.492724695754, 6743.552004804791, 6745.378676498945, 6492.531516226708, 6216.2939054956005, 6082.751484571885], \"Total\": [29412.0, 15330.0, 18964.0, 43823.0, 42482.0, 13343.0, 34106.0, 43922.0, 102377.0, 18047.0, 13389.0, 25167.0, 59235.0, 81163.0, 9461.0, 33842.0, 11960.0, 13985.0, 104097.0, 9122.0, 9197.0, 11992.0, 46250.0, 8067.0, 25478.0, 31646.0, 21593.0, 11780.0, 12493.0, 6543.0, 580.7714885309247, 574.84468319244, 369.40022637907515, 272.60374347034957, 551.1266423633106, 221.24274950339284, 230.13248962351642, 174.8201158373391, 174.82011777218995, 487.9360612364446, 160.99208937477076, 150.1271943370083, 282.47178789437805, 148.15177524269404, 143.21341859476863, 336.8003334723029, 140.24957571885705, 132.34827679935267, 132.3482888118607, 253.8277383606152, 130.37286560482409, 127.40974192152304, 127.40964480747716, 123.45884427570286, 122.47116218038394, 122.4711543925149, 125.43434681122505, 119.5079938087414, 372.3743861220206, 115.55711321111723, 3930.311383919834, 828.7270470025236, 888.859519525749, 328.88140552063555, 305.1650511725682, 354.5133673200894, 206.41991053997415, 203.47114628612954, 180.73328770643565, 1923.2702306475267, 958.9363809539607, 880.6868093080685, 391.1034715878801, 763.5921135984745, 4259.01015405402, 19524.37295958811, 339.6434068365368, 6817.619508408308, 2566.6762690781175, 1432.064198869244, 440.3613635120379, 5433.658345091054, 5774.812381371645, 1321.5364110949467, 1112.2362416423034, 6107.062369483024, 13184.517802882423, 2999.7461443635893, 1647.5689827815222, 6900.218725415393, 10686.944148772434, 4328.32668960928, 1040.3332305678648, 13741.469506118929, 4153.898207488658, 5173.153506932399, 5981.0256016706835, 12225.694903300013, 21507.682036859296, 11969.213032335607, 8489.172616993801, 5069.632853869722, 15056.889126209862, 4996.928764173925, 15478.81968639083, 29627.048991875337, 8419.869356284493, 19519.89449011788, 44387.85644217983, 92997.00099921845, 73670.9061652982, 6968.486898116283, 81163.33515873912, 24490.917999007324, 15190.926354452888, 9182.743466135593, 13199.77563054578, 68719.9848272552, 25219.575093198815, 33531.403631424015, 52658.80136000647, 39721.17978380014, 45103.57698404188, 102377.87652988848, 104097.34698664573, 64195.966892290424, 47778.17362769352, 51804.75392243999, 66776.51721200139, 42458.80986976696, 29504.173924655104, 34946.61915943417, 33495.80656228842, 37156.958739025955, 30736.879301894034, 44902.58550230092, 45613.73510210404, 59235.17308665121, 39263.363555684286, 52418.181066624646, 804.2995920954172, 401.64661818571926, 399.6582041661066, 286.31880058518277, 274.38836789922425, 271.4057619263516, 288.3062686021841, 1103.5010125819772, 239.59119254398425, 217.71871090156404, 209.76506644676985, 273.3922245922394, 187.8923412396228, 182.9214936452438, 180.93313747530138, 175.96207829273087, 168.00843560695424, 166.01997469807955, 430.4699178652758, 153.09537687817064, 147.13014828599017, 135.19970127412918, 135.19964038897356, 359.87394014021055, 129.23448198616666, 126.25182318877935, 122.27503717620465, 121.28082776145943, 159.05896843516012, 586.5272078210039, 2049.5637167241457, 405.58635484186567, 348.9255797211673, 621.3125202950514, 253.48163523774502, 983.0205250568765, 546.5816251195256, 11992.906962836705, 2102.916784329183, 1581.8327348081457, 385.6680870197005, 4442.040116089921, 832.9211220073973, 2158.928020658311, 2762.614386327008, 4659.396590072902, 18047.877586931845, 6429.2546649952465, 1875.1537317294433, 788.929543859158, 3746.1582152765473, 677.7423576427249, 4800.703966704178, 1088.5700120821866, 681.7118854882909, 2431.4043227314028, 1411.9356477727265, 12493.730668274158, 1853.4473393646063, 2374.9002109415715, 2295.959273907562, 1058.2440981354039, 42482.236588835425, 3376.9918337027466, 25167.97871832583, 15848.172211193656, 5328.021773003267, 7795.621831395481, 15928.840912984562, 11075.648962625914, 4990.02566209128, 9467.155899823963, 5429.87843903401, 5261.878834426056, 9314.124038585365, 11935.492098337878, 24306.444851892527, 28807.63076773133, 6124.410912258433, 12550.5603314225, 81163.33515873912, 21593.07343934728, 13443.722047800979, 51804.75392243999, 36222.066561813284, 26694.461494195275, 25144.318965055973, 36403.49218971032, 33495.80656228842, 26552.394713600912, 22566.579263745425, 39721.17978380014, 68719.9848272552, 64195.966892290424, 33886.94175975454, 37156.958739025955, 104097.34698664573, 34946.61915943417, 73670.9061652982, 92997.00099921845, 27489.153044576666, 45613.73510210404, 66776.51721200139, 52658.80136000647, 477.6901244283024, 505.96444830115894, 721.4071231710271, 274.9186266343607, 262.2454210461587, 255.42138833018663, 252.49662409994298, 245.672777402576, 239.82352316901697, 221.30109253600278, 220.32638095195307, 214.4771022709182, 205.70332758200715, 196.929811304525, 197.90476778916394, 177.43234098675322, 173.53285336477035, 166.70885063208345, 165.73383510406023, 189.13437866187536, 155.01061407309174, 142.33719254280996, 185.23447320324394, 136.4880302272594, 135.51315740346007, 378.28163235938445, 322.70184936130653, 132.5888423268985, 194.98575395137976, 121.86510470520582, 18964.570227093704, 1727.5973378183871, 3669.105159180089, 1227.4553157427013, 735.1292445172213, 616.1617488997297, 827.8023292632562, 29412.56939233806, 797.5810091152038, 821.9403341110419, 3036.8061427248335, 442.6493292544255, 385.1175861391516, 468.00833122844574, 13389.995031680995, 7922.181065068091, 1552.0981801917094, 1555.328878131482, 805.4235558993724, 1428.7529966707623, 565.528494095504, 529.4200810610831, 636.6616098130836, 832.7189453161951, 5222.1175006184585, 2824.4834927451243, 13985.735271258236, 2564.061393599697, 1798.5661109346986, 1324.2109015797334, 2487.3125634782396, 6203.046287950114, 3953.4823339302197, 3498.642111035286, 4096.242215263342, 2455.104755375611, 3775.984605064711, 8335.823167357556, 3045.0490284182233, 1743.6232978246521, 4348.172152150913, 2051.724499036446, 2731.8444581149406, 5368.426602598411, 6625.621422179727, 3109.178831574423, 9069.35359663869, 25478.41117180394, 5718.084573197796, 9267.830911947662, 10720.915565106556, 46250.977809967495, 23749.46379879367, 7737.528151849173, 16691.023036408536, 102377.87652988848, 7839.829325337032, 13567.246106736844, 47778.17362769352, 66776.51721200139, 92997.00099921845, 52418.181066624646, 44902.58550230092, 43823.86903223861, 21728.663352173662, 14742.531302042245, 73670.9061652982, 35857.19200802793, 11780.919173463997, 104097.34698664573, 39263.363555684286, 42458.80986976696, 45613.73510210404, 32020.02655153323, 31646.48784485308, 52658.80136000647, 33842.92729021636, 43922.63945446267, 64195.966892290424, 30736.879301894034, 40871.23471445139, 4144.16152098811, 4962.370595766247, 2112.4006425554426, 2036.676727776706, 1794.753584525351, 1779.0187448211439, 2300.2313845844915, 1681.6594896532708, 1597.0846953499233, 1301.0730211557952, 1017.8459680301114, 1032.5973830310115, 825.0942025304523, 830.0113094582135, 788.7073850813846, 2936.481814773046, 597.9224702319838, 589.0715638823738, 993.2525555721854, 694.2947850118472, 447.4580813710322, 431.7232466585932, 516.2961804015728, 405.1707111601352, 382.55188389664863, 2946.30030232692, 379.601575673806, 376.6513036258548, 372.7176077551923, 368.78389738566165, 8067.971285594071, 9197.483046073403, 6543.423682161359, 13343.32492349277, 2329.681873390284, 2034.6402753302004, 1021.7671080498391, 1198.844511594893, 1370.8234086980747, 3299.479199647319, 3970.2083003626713, 1507.7511408894684, 2584.6847251043937, 2765.3507160359222, 1918.2679921702736, 7338.441976261091, 6645.5837608138845, 3892.355260624736, 2672.3197592060533, 2006.0194112483455, 6411.696899834912, 9191.314459250847, 5634.294574832897, 43823.86903223861, 4788.967127890714, 33842.92729021636, 5412.494059335224, 43922.63945446267, 12104.278336176742, 11858.887652387151, 59235.17308665121, 7669.296528680463, 8688.640576422778, 22292.9950613912, 6184.786174235501, 8332.50928197311, 52418.181066624646, 31646.48784485308, 102377.87652988848, 13064.99217019965, 21451.197133877813, 40871.23471445139, 104097.34698664573, 9471.087917694707, 68719.9848272552, 34106.10877890485, 64195.966892290424, 16431.672776532778, 22066.44368696419, 35857.19200802793, 44902.58550230092, 20622.349164382398, 66776.51721200139, 92997.00099921845, 1475.5273658731771, 3210.132663238792, 586.9197699289573, 478.26907693605926, 451.1070198908494, 360.8879632957009, 341.4856300878915, 381.26178124094287, 294.9210275856273, 289.1004678690614, 269.69852661757994, 261.9377881305095, 270.668810736245, 250.2966216457688, 260.96796703713807, 278.4300767005794, 226.04423858482667, 219.25366982601076, 213.43303712539105, 201.7921742269945, 1591.9680167844792, 189.18063921397203, 186.27035190118576, 174.62918548364593, 187.24073089752062, 169.7786933640058, 160.0777408980286, 150.37678130647913, 918.7493858516071, 147.46655134162432, 9461.14535679815, 2741.0130746145546, 6063.08653119036, 15330.277078712275, 1487.367661267105, 2575.3817789351806, 552.0075870958483, 1035.3256329802487, 1787.4813633675935, 3815.420945300866, 412.35699376175455, 9122.257828491414, 3713.4857722594124, 3084.9528526632766, 2746.407754189069, 1811.4730433822378, 1145.192193882436, 1484.0561042772285, 6490.307935741947, 4706.859924875359, 1757.371907095469, 1038.277771964055, 2810.2630307075938, 5699.315640623775, 11960.72026073883, 3504.960151879063, 2838.4298926372358, 2054.6121210621495, 3637.185563105537, 1493.8699629672976, 6708.274726573279, 34106.10877890485, 9438.348462452796, 10038.56266661549, 104097.34698664573, 14504.946056831099, 16093.087500416263, 7651.296152771245, 9549.511294372878, 59235.17308665121, 9287.006769658357, 28226.34590500947, 21593.07343934728, 23039.226603719344, 81163.33515873912, 21340.402163831277, 27097.896318245635, 43922.63945446267, 68719.9848272552, 102377.87652988848, 66776.51721200139, 31646.48784485308, 44387.85644217983, 39263.363555684286, 46250.977809967495, 32020.02655153323, 39721.17978380014, 64195.966892290424, 73670.9061652982, 51804.75392243999, 42458.80986976696, 43823.86903223861], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -9.1587, -9.1692, -9.612, -9.9167, -9.213, -10.1261, -10.0867, -10.3625, -10.3625, -9.3363, -10.4453, -10.5155, -9.8835, -10.5289, -10.5632, -9.7081, -10.5842, -10.6423, -10.6423, -9.9911, -10.6574, -10.6805, -10.6806, -10.7122, -10.7203, -10.7203, -10.6965, -10.745, -9.6085, -10.7788, -7.2555, -8.81, -8.7408, -9.7336, -9.8097, -9.6652, -10.2013, -10.2156, -10.3331, -7.997, -8.6863, -8.7727, -9.5703, -8.9215, -7.2468, -5.7851, -9.7167, -6.8133, -7.7708, -8.3322, -9.4673, -7.0559, -7.0029, -8.4226, -8.5933, -6.9924, -6.2881, -7.6688, -8.2273, -6.9178, -6.5155, -7.3564, -8.6683, -6.3074, -7.3975, -7.1986, -7.0735, -6.4325, -5.9293, -6.457, -6.7635, -7.2262, -6.27, -7.2425, -6.269, -5.7202, -6.8092, -6.0895, -5.4201, -4.8154, -5.1208, -6.9875, -5.0826, -6.015, -6.3874, -6.7771, -6.5026, -5.2958, -6.0378, -5.8406, -5.544, -5.7436, -5.66, -5.1448, -5.1405, -5.455, -5.656, -5.6064, -5.5107, -5.8531, -6.0496, -5.9787, -6.0193, -6.0044, -6.0773, -5.9721, -5.9966, -5.9473, -6.0547, -6.0563, -8.4146, -9.1099, -9.1149, -9.4492, -9.4919, -9.5028, -9.4428, -8.1006, -9.6279, -9.724, -9.7613, -9.4966, -9.872, -9.8988, -9.9098, -9.9378, -9.9842, -9.9962, -9.0434, -10.0776, -10.1176, -10.2026, -10.2026, -9.2237, -10.248, -10.2715, -10.3037, -10.3119, -10.0408, -8.7361, -7.4986, -9.1054, -9.2556, -8.6861, -9.5771, -8.2359, -8.8179, -5.7781, -7.4883, -7.7824, -9.1695, -6.7775, -8.4187, -7.4975, -7.2631, -6.7593, -5.4622, -6.4597, -7.654, -8.4869, -7.0072, -8.633, -6.784, -8.1838, -8.6301, -7.4416, -7.9472, -5.9201, -7.6989, -7.484, -7.5162, -8.2258, -4.8714, -7.1702, -5.3868, -5.8018, -6.7925, -6.4581, -5.8335, -6.1567, -6.8595, -6.3145, -6.7922, -6.8382, -6.3701, -6.1892, -5.6591, -5.535, -6.744, -6.218, -4.8666, -5.841, -6.1992, -5.2705, -5.5451, -5.7547, -5.8197, -5.6103, -5.7035, -5.8409, -5.958, -5.6366, -5.3446, -5.3993, -5.7514, -5.7155, -5.3892, -5.8215, -5.5683, -5.4958, -5.9313, -5.8539, -5.8823, -5.9058, -8.8728, -8.8157, -8.4613, -9.4265, -9.4738, -9.5003, -9.5119, -9.5393, -9.5635, -9.6441, -9.6486, -9.6756, -9.7175, -9.7614, -9.7565, -9.866, -9.8884, -9.9286, -9.9347, -9.8029, -10.0018, -10.0875, -9.8241, -10.1297, -10.1369, -9.1103, -9.2694, -10.159, -9.7736, -10.2437, -5.2226, -7.5948, -6.8516, -7.937, -8.449, -8.624, -8.3321, -4.7989, -8.3716, -8.3451, -7.0515, -8.9586, -9.0969, -8.9044, -5.5873, -6.1081, -7.7202, -7.7223, -8.3679, -7.8078, -8.7175, -8.7841, -8.6041, -8.3413, -6.5464, -7.1505, -5.5992, -7.2448, -7.5899, -7.8902, -7.2816, -6.3967, -6.8396, -6.9586, -6.8121, -7.31, -6.9024, -6.1615, -7.1376, -7.6524, -6.8179, -7.507, -7.2625, -6.6629, -6.4982, -7.1524, -6.2481, -5.3847, -6.6544, -6.2667, -6.1667, -5.0326, -5.5832, -6.463, -5.898, -4.5854, -6.4641, -6.1271, -5.3539, -5.2084, -5.0477, -5.4452, -5.5388, -5.5983, -5.9615, -6.1649, -5.3798, -5.7549, -6.2879, -5.3696, -5.7991, -5.8241, -5.8062, -5.9328, -5.9535, -5.8499, -5.969, -5.9291, -5.9971, -6.0733, -6.0602, -6.5379, -6.3577, -7.2119, -7.2485, -7.375, -7.3838, -7.1269, -7.4401, -7.4917, -7.6968, -7.9425, -7.9281, -8.1526, -8.1467, -8.1978, -6.8835, -8.475, -8.49, -7.9679, -8.326, -8.7653, -8.8012, -8.6224, -8.8648, -8.9224, -6.8809, -8.9301, -8.9379, -8.9484, -8.9591, -5.8741, -5.7456, -6.0863, -5.3817, -7.1173, -7.2534, -7.9403, -7.7825, -7.6506, -6.7811, -6.606, -7.5598, -7.0418, -6.9763, -7.3323, -6.0441, -6.1448, -6.6614, -7.021, -7.298, -6.2546, -5.9626, -6.4012, -4.8762, -6.632, -5.1439, -6.5401, -4.9746, -5.9579, -6.0016, -4.9579, -6.3639, -6.2868, -5.6972, -6.5105, -6.3464, -5.2724, -5.5799, -4.9464, -6.1238, -5.895, -5.7242, -5.4575, -6.3419, -5.6596, -5.9133, -5.7556, -6.18, -6.1118, -6.0145, -6.0516, -6.1674, -6.0656, -6.0773, -7.4305, -6.6538, -8.3532, -8.5582, -8.6168, -8.8404, -8.8957, -8.7856, -9.0427, -9.0627, -9.1323, -9.1616, -9.1288, -9.2072, -9.1655, -9.1009, -9.3095, -9.3401, -9.3671, -9.4235, -7.3581, -9.4882, -9.5038, -9.5686, -9.4988, -9.5969, -9.656, -9.7188, -7.909, -9.7385, -5.5881, -6.8217, -6.0392, -5.1212, -7.4313, -6.891, -8.4187, -7.7998, -7.2596, -6.5101, -8.7142, -5.6489, -6.5424, -6.7297, -6.8505, -7.2588, -7.7087, -7.4589, -6.021, -6.3351, -7.2983, -7.8137, -6.8504, -6.1789, -5.5148, -6.6714, -6.8896, -7.194, -6.7037, -7.4901, -6.2929, -5.0378, -6.1073, -6.1121, -4.5141, -5.9159, -5.8651, -6.3477, -6.2419, -5.2194, -6.3101, -5.7152, -5.8647, -5.8468, -5.27, -5.9202, -5.8326, -5.6351, -5.4642, -5.3532, -5.6068, -5.8774, -5.8425, -5.908, -5.8829, -5.9745, -5.9571, -5.9104, -5.9101, -5.9483, -5.9918, -6.0135], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1765, 1.1763, 1.1757, 1.1749, 1.1746, 1.1742, 1.1742, 1.1733, 1.1733, 1.1731, 1.1729, 1.1725, 1.1725, 1.1724, 1.172, 1.1719, 1.1719, 1.1718, 1.1718, 1.1718, 1.1717, 1.1716, 1.1716, 1.1714, 1.1714, 1.1714, 1.1712, 1.1712, 1.1711, 1.1709, 1.1676, 1.1696, 1.1688, 1.1702, 1.1689, 1.1636, 1.1683, 1.1684, 1.1694, 1.1408, 1.1475, 1.1462, 1.1603, 1.14, 1.0959, 1.035, 1.1549, 1.059, 1.0784, 1.1004, 1.1447, 1.0432, 1.0353, 1.0904, 1.0921, 0.9899, 0.9247, 1.0244, 1.0652, 0.9424, 0.9073, 0.9702, 1.0839, 0.864, 0.9702, 0.9497, 0.9297, 0.8558, 0.7941, 0.8525, 0.8895, 0.9423, 0.8099, 0.9404, 0.7833, 0.6829, 0.852, 0.7308, 0.5787, 0.4438, 0.3713, 0.8629, 0.3127, 0.5785, 0.6836, 0.7974, 0.709, 0.266, 0.5264, 0.4387, 0.284, 0.3663, 0.3228, 0.0183, 0.006, 0.1749, 0.2693, 0.2379, 0.0798, 0.1902, 0.3577, 0.2592, 0.261, 0.1722, 0.289, 0.0151, -0.0251, -0.2371, 0.0668, -0.2238, 1.595, 1.594, 1.594, 1.5932, 1.5931, 1.5931, 1.5927, 1.5927, 1.5927, 1.5924, 1.5922, 1.5921, 1.5917, 1.5917, 1.5916, 1.5915, 1.5913, 1.5912, 1.5912, 1.5908, 1.5906, 1.5902, 1.5902, 1.5901, 1.5899, 1.5897, 1.5895, 1.5895, 1.5895, 1.5892, 1.5756, 1.5888, 1.5891, 1.5816, 1.5872, 1.573, 1.5779, 1.5294, 1.5601, 1.5508, 1.575, 1.5232, 1.5559, 1.5247, 1.5125, 1.4936, 1.4366, 1.4712, 1.5091, 1.5419, 1.4639, 1.5478, 1.439, 1.5231, 1.5449, 1.4617, 1.4996, 1.3465, 1.4759, 1.4428, 1.4444, 1.5094, 1.1713, 1.4046, 1.1795, 1.227, 1.3263, 1.2802, 1.1901, 1.2303, 1.3249, 1.2294, 1.3076, 1.2931, 1.1901, 1.123, 0.9419, 0.8961, 1.2355, 1.044, 0.5287, 0.8784, 0.9941, 0.5738, 0.657, 0.7526, 0.7474, 0.5869, 0.5769, 0.6717, 0.7173, 0.4733, 0.2171, 0.2305, 0.5174, 0.4611, -0.2428, 0.4164, -0.0762, -0.2366, 0.5467, 0.1176, -0.2918, -0.0779, 1.6578, 1.6574, 1.6571, 1.6565, 1.6564, 1.6563, 1.6562, 1.6562, 1.6561, 1.6559, 1.6558, 1.6557, 1.6556, 1.6553, 1.6552, 1.655, 1.6548, 1.6547, 1.6545, 1.6542, 1.6542, 1.6539, 1.6538, 1.6536, 1.6536, 1.6536, 1.6534, 1.6533, 1.653, 1.6529, 1.6267, 1.6503, 1.6402, 1.6499, 1.6505, 1.6521, 1.6487, 1.6115, 1.6463, 1.6428, 1.6295, 1.6482, 1.6491, 1.6467, 1.61, 1.614, 1.632, 1.6278, 1.6403, 1.6272, 1.6442, 1.6437, 1.6392, 1.6336, 1.5925, 1.6029, 1.5546, 1.6053, 1.6149, 1.6208, 1.599, 1.5701, 1.5776, 1.5809, 1.5696, 1.5837, 1.5607, 1.5097, 1.5406, 1.5834, 1.5042, 1.5661, 1.5244, 1.4484, 1.4026, 1.505, 1.3388, 1.1693, 1.3938, 1.2986, 1.2529, 0.9251, 1.041, 1.2827, 1.079, 0.5777, 1.2685, 1.057, 0.5713, 0.382, 0.2115, 0.3873, 0.4485, 0.4133, 0.7516, 0.9361, 0.1124, 0.4574, 1.0374, -0.2231, 0.3224, 0.2191, 0.1653, 0.3926, 0.3836, -0.0219, 0.3011, 0.0802, -0.3672, 0.2931, 0.0211, 1.8322, 1.8322, 1.832, 1.832, 1.8319, 1.8319, 1.8319, 1.8319, 1.8319, 1.8318, 1.8316, 1.8316, 1.8314, 1.8314, 1.8314, 1.8311, 1.8311, 1.831, 1.8307, 1.8307, 1.8306, 1.8306, 1.8305, 1.8304, 1.8303, 1.8303, 1.8303, 1.8303, 1.8303, 1.8302, 1.8298, 1.8272, 1.827, 1.819, 1.8287, 1.8281, 1.8299, 1.828, 1.8257, 1.8169, 1.8069, 1.8214, 1.8004, 1.7983, 1.8081, 1.7546, 1.7531, 1.7714, 1.7878, 1.7977, 1.6791, 1.611, 1.6617, 1.1354, 1.5935, 1.1262, 1.563, 1.0348, 1.3403, 1.3171, 0.7524, 1.3906, 1.343, 0.9903, 1.4592, 1.3252, 0.5601, 0.7573, 0.2167, 1.098, 0.831, 0.3572, -0.311, 1.2017, -0.0979, 0.349, -0.1258, 0.8126, 0.5859, 0.1978, -0.0643, 0.598, -0.4751, -0.8181, 1.9723, 1.9716, 1.9715, 1.9712, 1.971, 1.9706, 1.9705, 1.9704, 1.9702, 1.9701, 1.9699, 1.9698, 1.9698, 1.9697, 1.9696, 1.9695, 1.9693, 1.9692, 1.9691, 1.9688, 1.9687, 1.9686, 1.9686, 1.9683, 1.9683, 1.9682, 1.9679, 1.9676, 1.9675, 1.9675, 1.9565, 1.9618, 1.9503, 1.9407, 1.9635, 1.9547, 1.9672, 1.9572, 1.9514, 1.9426, 1.9635, 1.9321, 1.9374, 1.9356, 1.9309, 1.9389, 1.9475, 1.9381, 1.9005, 1.9077, 1.9297, 1.9406, 1.9081, 1.8725, 1.7953, 1.8662, 1.8589, 1.8777, 1.7969, 1.9003, 1.5956, 1.2245, 1.4397, 1.3733, 0.6324, 1.2014, 1.1483, 1.4092, 1.2934, 0.4909, 1.2531, 0.7363, 0.8547, 0.8078, 0.1253, 0.811, 0.6598, 0.3742, 0.0976, -0.1901, -0.0163, 0.4597, 0.1563, 0.2135, 0.0748, 0.3509, 0.1528, -0.2805, -0.4179, -0.104, 0.0515, -0.0019]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 1, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 5, 1, 2, 3, 5, 4, 2, 2, 1, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 5, 1, 3, 4, 5, 1, 2, 3, 5, 5, 5, 3, 4, 2, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 5, 5, 4, 1, 2, 3, 4, 5, 2, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 3, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 5, 1, 2, 5, 1, 5, 3, 4, 3, 4, 3, 1, 4, 5, 3, 4, 1, 2, 3, 5, 1, 3, 1, 2, 3, 4, 5, 1, 4, 1, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 3, 1, 1, 5, 3, 5, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 4, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 3, 5, 4, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 5, 1, 2, 3, 4, 2, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 3, 3, 1, 2, 3, 4, 5, 1, 3, 5, 2, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 3, 3, 4, 1, 2, 3, 4, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 4, 5, 3, 5, 1, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 5, 1, 5, 4, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 4, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 5, 1, 2, 1, 1, 5, 2, 3, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 5, 3, 4, 2, 3, 4, 5, 4, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 5, 1, 2, 3, 4, 3, 3, 1, 2, 3, 4, 5, 2, 3, 4, 3, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 4, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 4, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 4, 2, 3, 4, 5, 1, 2, 3, 5, 2, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 5, 1, 4, 5, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 5, 5, 2, 2, 3, 2, 3, 4, 1, 2, 3, 4, 5, 2, 2, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 3, 5, 1, 3, 5, 1, 2, 3, 4, 5, 5, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 3, 4, 3, 4, 1, 2, 3, 4, 5, 1, 2, 4, 1, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 1, 2, 3, 5, 5, 2, 2, 4, 4, 4, 2, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 2, 3, 4, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 3, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 3, 3, 4, 4, 3, 3, 3, 1, 2, 3, 4, 5, 5, 5, 2, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 1, 3], \"Freq\": [0.3667987435956489, 0.2552496798980041, 0.13176840243239452, 0.1411147839738813, 0.10505332852631147, 0.062211681589085556, 0.26309267865300257, 0.10547232571931102, 0.5691846078161084, 0.035925779700901966, 0.23314489399257543, 0.04501902684511367, 0.00029813925062989184, 0.6857202764487512, 0.0053117728185529955, 0.02150003283700022, 0.9214661132375507, 0.027064747218341456, 0.025041214716035553, 0.9965372577586047, 0.9967840612864955, 0.015885330971553334, 0.043057607633420876, 0.10367268634066386, 0.8373241562110876, 0.007703794718991895, 0.037440442334300605, 0.024652143100774064, 0.9301561743710813, 0.006132091818068354, 0.004088061212045569, 0.05995823111000168, 0.9251282522859123, 0.004769404747386498, 0.9955722070656274, 0.000906206689978648, 0.9968273589765129, 0.001812413379957296, 0.013877704532938406, 0.04412398364318878, 0.0042700629332118175, 0.937278813839994, 0.9978743719798538, 0.9911268965988211, 0.9949623544675896, 0.005442772394924264, 0.0008246624840794339, 0.01583351969432513, 0.9777198411245768, 0.009694395564654705, 0.00026928876568485294, 0.024505277677321614, 0.9651309362145128, 0.18045583070251867, 0.16860038402172478, 0.19577887838876215, 0.14226536016952654, 0.31288070153225583, 0.4210275481307718, 0.34393608820292915, 0.05477842909368522, 0.022633372524763776, 0.1576327534468306, 0.3998112412996054, 0.360910849467662, 0.04511012437303642, 0.01982337695810469, 0.17438003736790583, 0.012723028328803513, 0.019458749208758314, 0.005238894017742623, 0.9564723649535818, 0.0063615141644017565, 0.24278444430914245, 0.4302765201874418, 0.13407275515852812, 0.13407275515852812, 0.058813698127658326, 0.016140575855747862, 0.9808503789262163, 0.002483165516268902, 0.9967848210541976, 0.025808326865179015, 0.016058514493889165, 0.9268056936473175, 0.028675918739087793, 0.0028675918739087796, 0.41113477643194885, 0.12678580547244636, 0.25503565026905495, 0.06994854548774947, 0.13706661494878536, 0.0019245649908560597, 0.028593537007004316, 0.13087041937821206, 0.8385604603015688, 0.006112511102846909, 0.011351806333858546, 0.007858942846517454, 0.9753821288399996, 0.0017070945471970751, 0.03243479639674443, 0.007966441220253017, 0.9576800409775592, 0.03369233518608187, 0.3259044749446158, 0.05361107422691014, 0.5867551957878031, 0.9974099724372227, 0.9975459927643838, 0.023458661763463135, 0.9758803293600664, 0.0009345408164450178, 0.9987126191742424, 0.9996425916012306, 0.37245509350134776, 0.14786095086641338, 0.2368413064531145, 0.09642286283005676, 0.1464007121034765, 0.6921748518329853, 0.0012618808467498295, 0.10805684935063013, 0.05087372255844049, 0.14764005906973005, 0.9918826747276379, 0.007240019523559401, 0.967387321636256, 0.024979484830983133, 0.00681258677208631, 0.9931800638790886, 0.9102852549303659, 0.07209228523735739, 0.014418457047471477, 0.0019224609396628638, 0.0009612304698314319, 0.9938376514111741, 0.36087674566213096, 0.4280092061732261, 0.0019089799197467804, 0.012169746988385726, 0.19702263588386562, 0.3098100351369046, 0.5477649696874347, 7.438416209769618e-05, 0.0024546773492239737, 0.13991660890576652, 0.9940022608797984, 0.002307298602751092, 0.028397521264628824, 0.11855965127982535, 0.8430514125436682, 0.007809318347772927, 0.9973684825539461, 0.996690512128344, 0.9988149194990391, 0.9981809275000283, 0.0007551667176331488, 0.004531000305798893, 0.9620823982646316, 0.02416533496426076, 0.008306833893964636, 0.998504962004227, 0.9928451341868911, 0.3659226638954692, 0.3400719982847893, 0.06492176294919615, 0.11479348085107864, 0.11429181268283485, 0.11578619934759544, 0.005467681635858673, 0.8568178751722062, 0.01254350492932284, 0.009327221614111855, 0.03789948336551229, 0.004990878467886393, 0.06784475417283065, 0.8579632016200952, 0.031192990424289954, 0.012339021363859457, 0.004664751979020039, 0.04107991258943453, 0.9237713677162587, 0.01820758030520725, 0.0008584863121630798, 0.0012877294682446198, 0.9962733652652541, 0.0012877294682446198, 0.012729281640717533, 0.0012123125372111936, 0.984700858349792, 0.0015153906715139921, 0.016450488871124186, 0.001993998651045356, 0.006480495615897407, 0.9660923464314749, 0.008972993929704102, 0.4812537168308568, 0.07971037941580224, 0.40338422377569666, 0.015463445429393506, 0.02015770564903082, 0.9179704470809313, 0.05664264267002808, 0.021578149588582125, 0.0044954478309546094, 0.7495430105005069, 0.06879351220058086, 0.14865995273481686, 0.03274759656123541, 0.00023559421986500293, 0.7306351038751202, 0.1681042918278414, 0.09569573322667162, 0.005530703973556686, 0.7902648042032507, 0.0334771996645793, 0.14767647817405327, 0.028549819627368495, 0.00014492294227090607, 0.00036605305145741415, 0.8737686338288475, 0.12592224970135046, 0.9952509331099456, 0.17705511794086298, 0.6914362018517379, 0.004606209411861368, 0.030855293183564503, 0.09609941005842278, 0.13674738140882758, 0.8526210312475847, 0.0013852044308025485, 0.00022163270892840777, 0.009031532888832617, 0.10197214454703227, 0.8869957970122807, 0.001079070312667008, 0.010251167970336577, 0.9932673906316861, 0.9911577483808213, 0.002250074343656802, 0.005625185859142005, 0.9896283956488241, 0.006553830434760425, 0.02493571936539363, 0.9747599388290238, 0.0020364522907801823, 0.9978616224822894, 0.9929011286102077, 0.003863518754467378, 0.011590556263402134, 0.9842314027005645, 0.0014403104006937577, 0.9981351076807741, 0.029385903728306816, 0.022304963070883484, 0.9449515307331432, 0.003186423295840498, 0.9912387703522668, 0.006081219450013907, 0.47997246707315994, 0.16000515973762477, 0.23505059050435081, 0.07061518037614126, 0.05436734459902089, 0.9882767581206487, 0.004844493912356121, 0.9977852708012601, 0.0016934695299094611, 0.013348524529874577, 0.43263165696451705, 0.003287323205118366, 0.5490825911094677, 0.9952507843920856, 0.9991031083329953, 0.062342685485681386, 0.7291272104950884, 0.04271628449944836, 0.03873969344995016, 0.1269943593226843, 0.010994851726736152, 0.9801124967833369, 0.007853465519097252, 0.0036240535861622896, 0.006040089310270482, 0.9893666290223051, 0.12432911145791359, 0.07495933954843023, 0.6861364373493382, 0.11192204836024239, 0.0027140450526155773, 0.9933736057770481, 0.2688721414058723, 0.11623888449120172, 0.3005812612874693, 0.19502363705541592, 0.11930660936980829, 0.003852533597472102, 0.021188934786096562, 0.005778800396208153, 0.9679490663648657, 0.5492943781090284, 0.09984712836433492, 0.11293629388321547, 0.07533591995720577, 0.16258951385501016, 0.6101010421450229, 0.10275871027064963, 0.11836012880629598, 0.04561933774347225, 0.12316562903035583, 0.9944814028174545, 0.005731881284250458, 0.9961412818763556, 0.0018144649943103016, 0.9924917378094874, 0.007275249469233678, 0.9918590109721914, 0.033122215215509246, 0.9666166473726115, 0.9961934760010149, 0.03153542807876272, 0.005639547357150998, 0.018184662906731788, 0.6129842698813512, 0.3316974588430444, 0.9957492901307139, 0.7803009568620412, 0.015214781888674898, 0.15749807185859072, 0.042467632963993675, 0.004514275944991453, 0.001326478850362626, 0.009285351952538382, 0.9888899829453378, 0.08350627241250905, 0.825882956590382, 0.0026650938003992247, 0.08765197387979673, 0.9989762585812986, 0.9982708048011916, 0.7298571518265815, 0.06543744813860031, 0.1704817727821429, 0.02453904305197512, 0.009758215950493029, 0.9954282668413131, 0.31903532604717444, 0.36452546725038787, 0.1097147487715184, 0.1439697041340831, 0.06274123339863497, 0.1772194904902259, 0.17188076961579588, 0.18841778305610352, 0.15056929035282726, 0.3119028309240175, 0.999580118111005, 0.03823153308266873, 0.0019971696386468737, 0.019686386438090613, 0.04108463256644998, 0.8987263373910932, 0.02897769352063752, 0.06692467313099618, 0.8562218490264563, 0.014028883371102292, 0.03380730910741044, 0.9910903422527143, 0.3133965492045366, 0.08088603668170291, 0.538791111597642, 0.04576945438470123, 0.021221531747828353, 0.22956690511662997, 0.08772132551473209, 0.612518570909579, 0.032929839868841265, 0.03728646945816353, 0.14887111868588881, 0.0336012447830875, 0.2790663746677381, 0.47983189873616294, 0.058629962423337185, 0.24621228240629323, 0.0903694081635372, 0.2802271979130669, 0.2801890432125545, 0.1029986140331301, 0.9997197211107174, 0.9939977084882011, 0.9965661284675708, 0.3442627340620887, 0.39683802962610526, 0.07396696310009213, 0.06876969176210194, 0.11618537737463555, 0.004269225184447346, 0.01609169492599384, 0.8879988383650479, 0.06633719132756645, 0.02528694916941889, 0.008960921097900027, 0.9270480190372937, 0.02240230274475007, 0.0415460887266274, 0.04478732040145913, 0.024253061589237797, 0.22733203062978893, 0.6884635749798302, 0.015198585262589019, 0.038419004098344624, 0.9604751024586156, 0.40178996065565387, 0.2518626865752076, 0.04793365435513831, 0.1451106257527138, 0.15331784525978664, 0.401249175706274, 0.35017448461909284, 0.028593096292396317, 0.12786861764347718, 0.09214543627053419, 0.03845451168908389, 0.0033992938509687415, 0.00403666144802538, 0.01699646925484371, 0.9369303676732593, 0.01458693281524577, 0.009724621876830514, 0.0019449243753661028, 0.010697084064513565, 0.9633858739313429, 0.003768919938554444, 0.9956230171014657, 0.9974894635080108, 0.9984328864419261, 0.5213014077919761, 0.19524516102287143, 0.11463317638446817, 0.09805874963638525, 0.0707387017190907, 0.9961529358088284, 0.9971400060657232, 0.9904477352545987, 0.8124898183387214, 0.0012036886197610687, 0.17525706303721159, 0.0014444263437132824, 0.009388771234136336, 0.42528777721524824, 0.20499482786634265, 0.1506754110079672, 0.11393774825926184, 0.10511361441859512, 0.9969293804922905, 0.7886844471859331, 0.007404548222755525, 0.01220749842129965, 0.01801106324454047, 0.17370669884734585, 0.08359162048283951, 0.48793424565495686, 0.059648757441494345, 0.04191158810912452, 0.3269103872511713, 0.9906674274853176, 0.008961629689423102, 0.014146059983759183, 0.984919426369233, 0.8669676631887643, 0.05731298015644989, 0.05956657365679287, 0.007733923148904319, 0.008399757592187472, 0.8287126762107105, 0.04977843382099506, 0.09759192946484559, 0.0076960078604827896, 0.016374484809537848, 0.9950789667926979, 0.8879932346669507, 0.07583292076690015, 0.019508275555121316, 0.009094083341485124, 0.007627295705761717, 0.9985186478780121, 0.9163576499542961, 0.02724102014727883, 0.00983703505318402, 0.0022700850122732356, 0.04464500524137364, 0.9252378497040973, 0.01815561063570304, 0.024440245086523326, 0.03142317225410142, 0.013382966553036842, 0.9830397249867061, 0.0036498999690100474, 0.999421475358326, 0.09435286054351523, 0.029506466093766445, 0.48512700115544277, 0.24982141292722257, 0.14115622055431717, 0.9933422903117103, 0.0019573932104912165, 0.9972918407452747, 0.02088869815005933, 0.002695315890330236, 0.00673828972582559, 0.004042973835495354, 0.9655969177108071, 0.9927697547638487, 0.004914701756256677, 0.029329543408538584, 0.0008820915310838672, 0.7257408071992517, 0.15513784802937516, 0.0889809831980851, 0.9915272004070926, 0.01155968373468826, 0.019277472581083067, 0.9531979211344707, 0.010947700478145939, 0.005031862331570183, 0.010282331614423487, 0.007487646611528898, 0.9677519595872526, 0.0057475597229341546, 0.008753164348688712, 0.9936231709696594, 0.0024655661810661523, 0.0024655661810661523, 0.6395526372501724, 0.003995923238185954, 0.18980635381383282, 0.019825926835614925, 0.14682456411078132, 0.30309825691710285, 0.12984682349524254, 0.19431759415851071, 0.22871831656934755, 0.14401326608121306, 0.006565397076599135, 0.9935634242586691, 0.9994273557689544, 0.10253250170245, 0.07697324695529748, 0.25706996104072477, 0.4935152286554236, 0.06991121009452354, 0.12673253209385477, 0.02688265832293889, 0.14821465637870326, 0.6022195511808364, 0.09600949401049604, 0.9904096930430933, 0.005533015044933482, 0.9968362226051961, 0.9698245039726469, 0.001042822047282416, 0.003128466141847248, 0.0260705511820604, 0.9988865537836453, 0.08974601723922015, 0.8826839650477892, 0.012754200023598013, 0.006221560987120981, 0.00855464635729135, 0.03766409100465328, 0.9296600023587591, 0.013779545489507298, 0.018372727319343064, 0.0034099014902141743, 0.9939862843974319, 0.0017049507451070871, 0.0017049507451070871, 0.5491831706980179, 0.3650741062610393, 0.06492202538363186, 0.014699326501954385, 0.006165550838319755, 0.9964243734307924, 0.9977755095258815, 0.09625606277583203, 0.8593358002566361, 0.013066433860972674, 0.0060976691351205805, 0.02482622433584808, 0.9953087906435423, 0.0036231386067031145, 0.994551547540005, 0.9923187171415514, 0.10693408643278217, 0.8743917990619033, 0.0008225698956367859, 0.012749833382370181, 0.0053467043216391084, 0.012875967791862503, 0.9850115360774815, 0.0027787508026015715, 0.9947927873313627, 0.0027787508026015715, 0.9894391571602841, 0.7629870509744001, 0.015158683131941724, 0.20333221262783557, 0.002900735661050577, 0.01562654372243375, 0.6835647781241538, 0.012087890771352729, 0.2909805778473378, 0.0009800992517313024, 0.012305690605070797, 0.9949075925830887, 0.08903912363608357, 0.00502940656521811, 0.8097344570001157, 0.007078424054751414, 0.08903912363608357, 0.07001287513669639, 0.9297529720725277, 0.0020370231306873743, 0.010484677878537955, 0.559642148933846, 0.2377325818402206, 0.1901021880491482, 0.30980616637748926, 0.15901461928826605, 0.15220368682433924, 0.11725562997840726, 0.26172617063425413, 0.23565210569667586, 0.6936839571140079, 0.07060534354590058, 0.38680723485534796, 0.49663924518311614, 0.01784249472454894, 0.01864089429393537, 0.0800482350871787, 0.9983502230062195, 0.9972614898171093, 0.998415244529114, 0.9625557767173204, 0.03012079301292295, 0.005238398784856165, 0.0013095996962140413, 0.0075554368696840015, 0.9840956522763411, 0.0018888592174210004, 0.0056665776522630005, 0.6740178005415246, 0.015440453784091287, 0.18644832477358766, 0.04890553771781215, 0.0751349278280258, 0.2782557969960133, 0.39103235525861024, 0.09842066834912071, 0.14676136688469163, 0.08555558238819777, 0.0055583140730837794, 0.931017607241533, 0.06299422616161617, 0.996032141523751, 0.004098897701743831, 0.44417109703260904, 0.3254183302297514, 0.05042649817810554, 0.017950121418367073, 0.16200425151078837, 0.9685622527606366, 0.030657890767335508, 0.3254813197053834, 0.41534872833200254, 0.04497801763117279, 0.005450538097176604, 0.2086714138179238, 0.0905280359700427, 0.9091740386668804, 0.9973683920284319, 0.9872688374088464, 0.0028207681068824183, 0.011283072427529673, 0.87418083698459, 0.024108987293680273, 0.04932220301302529, 0.002392494922273615, 0.04987431722585767, 0.9634631527448599, 0.029637020888535898, 0.0057194250837525416, 0.0010398954697731894, 0.1909760459351492, 0.6931331932668413, 0.07351732741751318, 0.02429451911785637, 0.018062446822406257, 0.24316045550941598, 0.6539909908439597, 0.05366949066422734, 0.03681538745563665, 0.012381645653238413, 0.9953803795603717, 0.04078054317650666, 0.9590709886332012, 0.06961783995805307, 0.929799804824382, 0.9996078340131707, 0.9962132281964897, 0.8934375527723784, 0.0036417291553221946, 0.03945206584932377, 0.035203381834781215, 0.02852687838335719, 0.3658264955286362, 0.3214741035157478, 0.18949344184632735, 0.03143421958195006, 0.09179976283735586, 0.39909439984367917, 0.3074117113014014, 0.14464918557466108, 0.029444908398877596, 0.11938207759000713, 0.3324154372259122, 0.5758308640536115, 0.014182633707145823, 0.012350046205660688, 0.06517637287890608, 0.24100277090253425, 0.6973731941224416, 0.01420544787840141, 0.010123422625987212, 0.03739135131211405, 0.9953088016592886, 0.9818373599215573, 0.015341208748774333, 0.9975633473337, 0.31363221321186524, 0.033610777217042836, 0.33900878955882174, 0.19876364591386358, 0.11499554785708958, 0.40311293918603003, 0.034283436884045546, 0.3368483719241935, 0.09996196248974451, 0.12581058553723917, 0.0014464711390148458, 0.011933386896872478, 0.9666043386466707, 0.01988897816145413, 0.99615287246405, 0.996074306498609, 0.9936236588484296, 0.005370938696477998, 0.9962834232055648, 0.9774957891639114, 0.02060985097634753, 0.982469909928951, 0.0018295529048956258, 0.014636423239165006, 0.9985846050902315, 0.06382366645771084, 0.011660312320303982, 0.28760582482409275, 0.4981075491974865, 0.13880563570334467, 0.12175126727772555, 0.037571309834730254, 0.27920949848585075, 0.3412700977418728, 0.2202140102928807, 0.06408995531606168, 0.07718115400406717, 0.2061351529064378, 0.45040553677358725, 0.20217364234693702, 0.002718134937000294, 0.9948373869421075, 0.0023919587445602585, 0.003931898968578947, 0.9957534137926184, 0.00014988767878077548, 0.009068204566236917, 0.986710589413845, 0.004046967327080938, 0.9980746609758677, 0.001006793281718694, 0.9987389354649444, 0.9954134800511377, 0.9954691633708924, 0.722269707845033, 0.016793084011203194, 0.13626626876752443, 0.09532790476011366, 0.029241688576721984, 0.7246213871743797, 0.028219254834085227, 0.13651575744373404, 0.08539391897618834, 0.025111047055258448, 0.16978073425320397, 0.28142951474096445, 0.11514508885376547, 0.367392083099808, 0.06629000661945526, 0.016276364116684396, 0.9775991197583566, 0.0010172727572927748, 0.005086363786463874, 0.035937909077054554, 0.9355529926787752, 0.011006505796220884, 0.0032519221670652613, 0.014258427963286146, 0.02528712367610185, 0.95585327495665, 0.0075861371028305554, 0.011379205654245833, 0.005128579805114135, 0.9949444821921423, 0.40908640993793693, 0.1875280056697209, 0.18612273251330982, 0.10554740815314519, 0.1117192159346803, 0.02262883587955753, 0.005451831746560065, 0.9517553942213901, 0.016579543119675817, 0.0035100834532647, 0.1066481356611853, 0.00671799279755498, 0.860862791343831, 0.024592652205335196, 0.0011996415709919607, 0.0016229504700440822, 0.9932456876669783, 0.004868851410132246, 0.9922257074489504, 0.9900847119894058, 0.9983247446965366, 0.17435447204309962, 0.28734454731907827, 0.017697240705876176, 0.013822696882696186, 0.5068322190321934, 0.9943828690152227, 0.29843645074967823, 0.3074408397669802, 0.008782969615237222, 0.11635589578505445, 0.26898767027505927, 0.2735899898368816, 0.5199444047456406, 0.022586602168488422, 0.013988059630757856, 0.1699137831618528, 0.021548185300352865, 0.9468526129037407, 0.012675403117854627, 0.01901310467678194, 0.11644913538315725, 0.10514513610867512, 0.2639394116311623, 0.43080797234970813, 0.08365856605916344, 0.8125541929270318, 0.05452453498173998, 0.12360434836962242, 0.007855229616013388, 0.001386216991061186, 0.8672143213093427, 0.07013214858831546, 0.039654967967220345, 0.005368139768488343, 0.017316579898349494, 0.002436974361006147, 0.9109410161440977, 0.08431931289081268, 0.0019495794888049174, 0.9473252107235686, 0.05148082660169249, 0.001170018786402102, 0.05671967414133141, 0.021644749212554056, 0.2756445773213209, 0.6429533636572533, 0.0029989712764382126, 0.001088436101726566, 0.004353744406906264, 0.9948305969780814, 0.06708630341133726, 0.7387095222659148, 0.1881457234482263, 0.006081477929639638, 0.9952784634364618, 0.9980331455847647, 0.2662708597782767, 0.13301050806892803, 0.2817299350293026, 0.1214552396994743, 0.19753262820755335, 0.006268955683318925, 0.9867336245543988, 0.00501516454665514, 0.9985552884746606, 0.0026853880756884945, 0.00244126188698954, 0.9140084504888839, 0.07299373042098725, 0.007567911849667575, 0.9974944183323673, 0.003972473823087247, 0.01112292670464429, 0.905988863252098, 0.07229902358018789, 0.006620789705145411, 0.05531226978945339, 0.0014092298035529526, 0.050732272927906295, 0.8923947730999072, 0.9991752798356837, 0.0014593144545881037, 0.0025538002955291816, 0.006931743659293493, 0.9890503715970873, 0.0033566783536674596, 0.0016783391768337298, 0.0005594463922779099, 0.015105052591503569, 0.9784717400940645, 0.02778199352565575, 0.0007862828356317665, 0.0010483771141756887, 0.9702730191695998, 0.030788745537771285, 0.0007175343239734834, 0.9684104157918485, 0.01849385584884995, 0.018091815504309734, 0.9411764465686463, 0.0064326455126434605, 0.015679573437068436, 0.625768212369112, 0.1279567204226913, 0.055607005796480403, 0.19068505938656835, 0.9991688643894236, 0.9986738453293011, 0.014149352744373919, 0.9797207003690631, 0.0009758174306464772, 0.004879087153232386, 0.01133196121596574, 0.9079733924292549, 0.0035412378799892937, 0.0042494854559871524, 0.07224125275178159, 0.47755233201730296, 0.19524980439126227, 0.10810761278728054, 0.09098933147972219, 0.12808888190934342, 0.39067843137139546, 0.35979323495881416, 0.07418238113346869, 0.050014714940623824, 0.12533598769180646, 0.2763187284468376, 0.6231833542109091, 0.0001675674520599379, 0.005027023561798137, 0.09534588022210466, 0.0023230426993808427, 0.9942622753350007, 0.004279769921029444, 0.9648503521965269, 0.0004755299912254938, 0.02900732946475512, 0.0014265899736764815, 0.9987815714717506, 0.012008853714986464, 0.9739180362854022, 0.0036026561144959393, 0.009607082971989171, 0.7960328249454772, 0.03556824667070612, 0.12584200316646568, 0.042333945765677394, 0.9948426391742157, 0.0822116562268493, 0.9166127188510784, 0.4403783692836228, 0.29955083719915787, 0.1028329079047573, 0.06921054645402584, 0.08805533775100839, 0.17977016310295207, 0.7791908004484589, 0.03425718157082079, 0.0003201605754282317, 0.006483251652421691, 0.9213408416659599, 0.00845266827216477, 0.057525103518899126, 0.012679002408247153, 0.1504678237801978, 0.3353158238608017, 0.09887331378917928, 0.2909949759925772, 0.12433113121895815, 0.9976310299733603, 0.17398577548932842, 0.7636980803301805, 0.0193317528321476, 0.013325771369732812, 0.02965453347067302, 0.03775275234081405, 0.018733373320631214, 0.9004889450382806, 0.021021418917044187, 0.022022438865474864, 0.052587207661611575, 0.8763644809800549, 0.020821330952313213, 0.04911698583622604, 0.00133470070207136, 0.005287066114010819, 0.993968429434034, 0.000422781793234565, 0.015748621797987545, 0.9838132328568328, 0.20774900484295988, 0.666407272899355, 0.07204112777758453, 0.0009662744411300459, 0.052823002781775846, 0.016142288969615805, 0.00017545966271321527, 0.07913230788366009, 0.9044945612866248, 0.1573642862525993, 0.06795778544491642, 0.547495043692884, 0.1567746308474373, 0.07046382091685477, 0.05472057900719126, 0.03380175626318341, 0.6764177866553269, 0.12997731936673168, 0.10497677511169791, 0.06658460035430906, 0.054072788196228114, 0.06538781832179698, 0.801408768316733, 0.012511812158080952, 0.04552129805409991, 0.020254889501136197, 0.1432459195647364, 0.7874349310183979, 0.003549825995044488, 0.30032620589687475, 0.22802342269752493, 0.2244499376576541, 0.1244142797623742, 0.12277003817961155, 0.0094274906077964, 0.030365289515809336, 0.9600693342218707, 0.010872174459344394, 0.006600963064601954, 0.9819903288457847, 0.9984553511399493, 0.005185806311990333, 0.980117392966173, 0.015557418935970999, 0.997971086710739, 0.13847624176553983, 0.7625211286799987, 0.031663163819038054, 0.017835579619584725, 0.04969914320962934, 0.9975395042616777, 0.9937591964015056, 0.996698901538651, 0.9902098026335617, 0.007890117949271408, 0.9983530823107211, 0.9689269074785375, 0.03086164005240199, 0.004905828320282415, 0.000545092035586935, 0.9808931180386896, 0.013354754871879908, 0.0002725460177934675, 0.9963527461472523, 0.9983900818370136, 0.05017121885307468, 0.010532126095111095, 0.9352527972458653, 0.004021357236315146, 0.00019149320172929266, 0.009036498500375868, 0.9894965857911576, 0.9968770365641022, 0.01975759965572377, 0.005597986569121735, 0.9704274364236325, 0.0006585866551907923, 0.0032929332759539616, 0.0007737887644765732, 0.025921923609965203, 0.9683966387424313, 0.004642732586859439, 0.010007972401217747, 0.9563173627830291, 0.033359908004059156, 0.011597204500153918, 0.9728765997351343, 0.015462939333538558, 0.4464313215614004, 0.1878489178475545, 0.2128791515718764, 0.06128606576210049, 0.09155581695799951, 0.9964198058737435, 0.9942821033417337, 0.042539965368548795, 0.9505481916834352, 0.007334476787680827, 0.24272148588963935, 0.13622494148324418, 0.24621094713189146, 0.28754066989726695, 0.08737248409171483, 0.03836266054025507, 0.9531645657309529, 0.007377434719279821, 0.008161830106405789, 0.9916623579283034, 0.014756864651194595, 0.23779633323639288, 0.12952310916705656, 0.5973578810803571, 0.02057528557080846, 0.004249427296891097, 0.10272528595962825, 0.11879920660439022, 0.7637883671890345, 0.010346431679387019, 0.04814280293994564, 0.9197809193263298, 0.014841014440133618, 0.015564966364042575, 0.001447903847817914, 0.9934803556573538, 0.9951788929678487, 0.15600632924736701, 0.6664012816743666, 0.13491251571532867, 0.026932279777513262, 0.01575758094208818, 0.13388881687917406, 0.7495563751007406, 0.11013137894600562, 0.0018416618552843749, 0.004604154638210937, 0.0028941929294206995, 0.00057883858588414, 0.9909716590336476, 0.00463070868707312, 0.00115767717176828, 0.9980494742485464, 0.0013861798253452034, 0.015315055795173524, 0.010801144613438169, 0.9145506476423094, 0.04916938965818868, 0.010317511272537952, 0.001239468962644389, 0.0008676282738510723, 0.9974006742399398, 0.0004957875850577556, 0.000681087139698352, 0.9988142903676333, 0.000340543569849176, 0.999810337798914, 0.28986734550415655, 0.15785495115493817, 0.028319135166267898, 0.03714867540822214, 0.4869168411477697, 0.18550928928935295, 0.02544998626571177, 0.08901631140864164, 0.22688017710147199, 0.4731703667696504, 0.9984572076181952, 0.059090186943286424, 0.94081854167963, 0.005196056628992341, 0.9945863688671223, 0.12713533061614674, 0.33082526891513453, 0.033679056302029095, 0.0699057902948021, 0.4384491167289987, 0.9897434630536499, 0.008650714072962492, 0.0012721638342591901, 0.9985305888405386, 0.03853601498511224, 0.8546663215346786, 0.07936336059096089, 0.026871059097726916, 0.0006249083511099283, 0.11747862024458934, 0.8581413192059967, 0.0012632109703719285, 0.02315886779015202, 0.9989165508018275, 0.009065923349293074, 0.9167248374961643, 0.07039422835921681, 0.0037330272614736187, 0.9985778901215653, 0.9945324680063715, 0.9996275118147994, 0.9993208279103284, 0.9994646692533874, 0.9997238022151316, 0.9938563133747342, 0.003433921043357604, 0.9026919942726301, 0.06481525969337477, 0.0010731003260492512, 0.02790060847728053, 0.9962908588049034, 0.0027996441717502473, 0.011198576687000989, 0.967976972382648, 0.017497776073439046, 0.002596609544698064, 0.9893082365299625, 0.005193219089396128, 0.27717760246358164, 0.6593298645757847, 0.0020661174495565145, 0.06142726109643022, 0.24296375362906253, 0.11131899606934674, 0.07892270346135821, 0.3396124118785333, 0.22719609479849387, 0.19482048328239465, 0.026057676848363378, 0.7666903040484903, 0.0005246512117120143, 0.011892094132138991, 0.010683570497293954, 0.9871619139499614, 0.04570505168372062, 0.002798268470431875, 0.6658946203471051, 0.09113027652039805, 0.19438638307933423, 0.2427408139591912, 0.07831185785696897, 0.4797952616521254, 0.049274633919390465, 0.14985629122215677, 0.9971105730797196, 0.7763651392515991, 0.005612643640544972, 0.17065470528684037, 0.013728222958630269, 0.03367586184326983, 0.7901952893772503, 0.005325829459107778, 0.1927161252425296, 0.009073635374776214, 0.0027615412010188476, 0.9986716143161983, 0.9975324946726674, 0.9946545971206678, 0.0029691182003602026, 0.0033616436138865927, 0.002689314891109274, 0.0033616436138865927, 0.9910125373737675, 0.04635159168777455, 0.1846672753118854, 0.18435052183793707, 0.5322514207245365, 0.052369907692793115, 0.00016523083363198008, 0.004626463341695443, 0.3040247338828434, 0.6113540844383264, 0.07980649264424639, 0.3292382218264771, 0.1675607845127557, 0.26261122497507583, 0.06843529837145076, 0.17217067993710725, 0.31265460202242934, 0.1149154317569439, 0.2979338461326348, 0.15005817425935813, 0.12444717687166715, 0.33353042251801013, 0.15140052854063768, 0.27876566160078836, 0.09951102988650222, 0.13679958736090259, 0.9973465210333284, 0.36079767584059097, 0.1524816571895035, 0.04300946371469731, 0.15329649875905707, 0.29040244981002794, 0.6813379505465239, 0.10354439851693113, 0.10851936512730904, 0.04244994874088825, 0.06411662575430985, 0.0030988356651169063, 0.9947262485025269, 0.9965808643434475, 0.9895723836553224, 0.9054511579813374, 0.05220759688876902, 0.035064803880516505, 0.0074025697081090405, 0.8577392473141671, 0.09467467790020344, 0.0443370850729826, 0.003000253877119123, 0.002572426591337404, 0.032298244980125186, 0.9243586218205739, 0.00400155247541374, 0.03687144780916946, 0.0596170494555741, 0.047240851847075174, 0.773512350531183, 0.10731068902003338, 0.01222526836937089, 0.0009337132220359356, 0.0016976604037017011, 0.5368851026706629, 0.4586229580600146, 0.0018674264440718712, 0.00417068264619922, 0.9959590159123738, 0.9980938417622084, 0.9955588847706605, 0.9996677294106243, 0.998557361968716, 0.9957479724118077, 0.998639443969515, 0.9966585507660692, 0.1942589804099993, 0.0886702175618324, 0.2084997703272737, 0.3607058198277149, 0.14794598414057278, 0.9963970198801343, 0.9975290439470075, 0.9911264502597037, 0.02903240889231344, 0.0023983294302345887, 0.9555449361513597, 0.004670430995719988, 0.008331039073446466, 0.9933356184629335, 0.1749060827070422, 0.07186147506655774, 0.6970347281230675, 0.01942202028825885, 0.036793938434979266, 0.6096118450728215, 0.3080968341633749, 0.05140572726016871, 0.017754046315724716, 0.013129893568092993, 0.7219826986344753, 0.2067728044616913, 0.029454138717116277, 0.041449574243038634, 0.0004750667535018755, 0.14264099927662988, 0.35780898320237264, 0.009651880086383848, 0.027438916245576938, 0.4623250561377863, 0.9927992961982015, 0.00393967974681826, 0.9947896110073534, 0.0035401765516275925], \"Term\": [\"10\", \"10\", \"10\", \"10\", \"10\", \"2015\", \"2015\", \"2015\", \"2015\", \"2016\", \"2016\", \"2016\", \"2016\", \"2016\", \"3d\", \"3d\", \"3d\", \"3d\", \"3d\", \"abalone\", \"abstention\", \"action\", \"action\", \"action\", \"action\", \"actions\", \"actions\", \"actions\", \"actions\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"adaptor\", \"admm\", \"admm\", \"admm\", \"adversarial\", \"adversarial\", \"adversarial\", \"adversarial\", \"afferent\", \"aga\", \"agd\", \"agent\", \"agent\", \"agent\", \"agent\", \"agents\", \"agents\", \"agents\", \"agents\", \"al\", \"al\", \"al\", \"al\", \"al\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithms\", \"algorithms\", \"algorithms\", \"algorithms\", \"algorithms\", \"analog\", \"analog\", \"analog\", \"analog\", \"analog\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"annotations\", \"annotations\", \"annotations\", \"anonymity\", \"appearance\", \"appearance\", \"appearance\", \"appearance\", \"appearance\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"arm\", \"arm\", \"arm\", \"arm\", \"armed\", \"armed\", \"armed\", \"armed\", \"arms\", \"arms\", \"arms\", \"arms\", \"arxiv\", \"arxiv\", \"arxiv\", \"arxiv\", \"atari\", \"auctions\", \"auditory\", \"auditory\", \"bandit\", \"bandit\", \"bandits\", \"based\", \"based\", \"based\", \"based\", \"based\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bethe\", \"bethe\", \"bic\", \"bic\", \"bic\", \"bidder\", \"bipartite\", \"bipartite\", \"bipartite\", \"bipartite\", \"bipartite\", \"blossom\", \"bound\", \"bound\", \"bound\", \"bound\", \"bound\", \"bounds\", \"bounds\", \"bounds\", \"bounds\", \"bounds\", \"bourlard\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"bsp\", \"buyer\", \"buyers\", \"calcium\", \"camera\", \"camera\", \"camera\", \"camera\", \"camera\", \"candes\", \"cands\", \"case\", \"case\", \"case\", \"case\", \"case\", \"categories\", \"categories\", \"categories\", \"categories\", \"categories\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cells\", \"cells\", \"cells\", \"cells\", \"cells\", \"chip\", \"chip\", \"chip\", \"chip\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circuits\", \"circuits\", \"circuits\", \"circuits\", \"circuits\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"clique\", \"clique\", \"clique\", \"clique\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clusters\", \"clusters\", \"clusters\", \"clusters\", \"clusters\", \"cnn\", \"cnn\", \"cnn\", \"coalescent\", \"convergence\", \"convergence\", \"convergence\", \"convergence\", \"convergence\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convexity\", \"convexity\", \"convexity\", \"convexity\", \"copeland\", \"copula\", \"copula\", \"copula\", \"copulas\", \"copulas\", \"cortex\", \"cortex\", \"cortical\", \"cortical\", \"cow\", \"critic\", \"critic\", \"critic\", \"currents\", \"currents\", \"cvpr\", \"cvpr\", \"cvpr\", \"cvpr\", \"dags\", \"dags\", \"data\", \"data\", \"data\", \"data\", \"data\", \"dcg\", \"dcg\", \"ddp\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deflation\", \"dendritic\", \"descent\", \"descent\", \"descent\", \"descent\", \"descent\", \"descriptor\", \"descriptor\", \"descriptor\", \"descriptors\", \"descriptors\", \"descriptors\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"diederik\", \"different\", \"different\", \"different\", \"different\", \"different\", \"discriminator\", \"discriminator\", \"discriminator\", \"discriminator\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distributions\", \"distributions\", \"distributions\", \"distributions\", \"distributions\", \"donoho\", \"donoho\", \"dpp\", \"dpp\", \"dpps\", \"dqn\", \"dqn\", \"dropout\", \"dropout\", \"dueling\", \"dynamics\", \"dynamics\", \"dynamics\", \"dynamics\", \"dynamics\", \"ecoc\", \"edges\", \"edges\", \"edges\", \"edges\", \"edges\", \"eeg\", \"eeg\", \"eeg\", \"eigenvalues\", \"eigenvalues\", \"eigenvalues\", \"eigenvalues\", \"electrode\", \"electrodes\", \"em\", \"em\", \"em\", \"em\", \"em\", \"epitome\", \"error\", \"error\", \"error\", \"error\", \"error\", \"et\", \"et\", \"et\", \"et\", \"et\", \"excitatory\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"face\", \"face\", \"face\", \"face\", \"face\", \"fci\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"features\", \"features\", \"features\", \"features\", \"features\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"firing\", \"fista\", \"fixations\", \"following\", \"following\", \"following\", \"following\", \"following\", \"frame\", \"frame\", \"frame\", \"frame\", \"frame\", \"frames\", \"frames\", \"frames\", \"frames\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frobenius\", \"frobenius\", \"function\", \"function\", \"function\", \"function\", \"function\", \"functions\", \"functions\", \"functions\", \"functions\", \"functions\", \"game\", \"game\", \"game\", \"game\", \"game\", \"games\", \"games\", \"games\", \"games\", \"games\", \"gan\", \"gan\", \"ganglion\", \"gans\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gbp\", \"gbs\", \"ggood\", \"gibbs\", \"gibbs\", \"gibbs\", \"gibbs\", \"gibbs\", \"given\", \"given\", \"given\", \"given\", \"given\", \"gool\", \"gp\", \"gp\", \"gp\", \"gp\", \"gp\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"grammar\", \"grammar\", \"grammars\", \"grammars\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graphical\", \"graphical\", \"graphical\", \"graphical\", \"graphical\", \"graphon\", \"graphs\", \"graphs\", \"graphs\", \"graphs\", \"graphs\", \"gsm\", \"hash\", \"hash\", \"hash\", \"hash\", \"hash\", \"hashing\", \"hashing\", \"hashing\", \"hashing\", \"hdp\", \"hdp\", \"hdp\", \"hebbian\", \"hidden\", \"hidden\", \"hidden\", \"hidden\", \"hidden\", \"homotopy\", \"hopfield\", \"hopfield\", \"horizon\", \"horizon\", \"horizon\", \"horizon\", \"horizon\", \"hsic\", \"hsic\", \"human\", \"human\", \"human\", \"human\", \"human\", \"hyperedge\", \"image\", \"image\", \"image\", \"image\", \"image\", \"images\", \"images\", \"images\", \"images\", \"images\", \"incoherence\", \"incoherence\", \"incoherence\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"information\", \"information\", \"information\", \"information\", \"information\", \"inhibition\", \"inhibition\", \"inhibitory\", \"input\", \"input\", \"input\", \"input\", \"input\", \"inputs\", \"inputs\", \"inputs\", \"inputs\", \"inputs\", \"interventional\", \"interventional\", \"investor\", \"ising\", \"ising\", \"ising\", \"ising\", \"isometry\", \"k2\", \"k2\", \"k2\", \"k2\", \"k2\", \"k22\", \"k22\", \"k22\", \"k22\", \"k2f\", \"k2f\", \"k2f\", \"k2f\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"keypoint\", \"keypoints\", \"kf\", \"kf\", \"kf\", \"kf\", \"kf\", \"kikuchi\", \"kingma\", \"kingma\", \"knng\", \"kx\", \"kx\", \"kx\", \"kx\", \"kx\", \"kxk\", \"kxk\", \"kxk2\", \"kxk2\", \"kxk2\", \"kzk\", \"label\", \"label\", \"label\", \"label\", \"label\", \"labels\", \"labels\", \"labels\", \"labels\", \"labels\", \"lanczos\", \"language\", \"language\", \"language\", \"language\", \"language\", \"lasso\", \"lasso\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"lemma\", \"lemma\", \"lemma\", \"let\", \"let\", \"let\", \"let\", \"let\", \"lexical\", \"lexicon\", \"lgn\", \"lifted\", \"lifted\", \"lifted\", \"lifted\", \"lighting\", \"lighting\", \"lighting\", \"lighting\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"lipschitz\", \"lipschitz\", \"lipschitz\", \"lmnn\", \"lmnn\", \"log\", \"log\", \"log\", \"log\", \"log\", \"loopy\", \"loopy\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"lstm\", \"lstm\", \"lvm\", \"mallows\", \"mallows\", \"mallows\", \"marginal\", \"marginal\", \"marginal\", \"marginal\", \"marginal\", \"marginals\", \"marginals\", \"marginals\", \"marginals\", \"matrices\", \"matrices\", \"matrices\", \"matrices\", \"matrices\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"mcts\", \"mdp\", \"mdp\", \"mdps\", \"mdps\", \"membrane\", \"memorability\", \"messages\", \"messages\", \"messages\", \"messages\", \"messages\", \"method\", \"method\", \"method\", \"method\", \"method\", \"methods\", \"methods\", \"methods\", \"methods\", \"methods\", \"min\", \"min\", \"min\", \"min\", \"min\", \"minimization\", \"minimization\", \"minimization\", \"minimization\", \"minimization\", \"minwise\", \"mln\", \"mln\", \"mmsb\", \"model\", \"model\", \"model\", \"model\", \"model\", \"models\", \"models\", \"models\", \"models\", \"models\", \"motor\", \"motor\", \"motor\", \"motor\", \"mplp\", \"multiarmed\", \"multilabel\", \"multilabel\", \"mwis\", \"ndcg\", \"ndcg\", \"nesterov\", \"nesterov\", \"nesterov\", \"nesterovs\", \"network\", \"network\", \"network\", \"network\", \"network\", \"networks\", \"networks\", \"networks\", \"networks\", \"networks\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neuron\", \"neuron\", \"neuron\", \"neuronal\", \"neuronal\", \"neurons\", \"neurons\", \"neurons\", \"neurons\", \"neurophysiol\", \"neurosci\", \"neurosci\", \"nmt\", \"nnz\", \"node\", \"node\", \"node\", \"node\", \"node\", \"nodes\", \"nodes\", \"nodes\", \"nodes\", \"nodes\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"norm\", \"norm\", \"norm\", \"norm\", \"norm\", \"norms\", \"norms\", \"norms\", \"norms\", \"nouns\", \"nouns\", \"number\", \"number\", \"number\", \"number\", \"number\", \"object\", \"object\", \"object\", \"object\", \"object\", \"objects\", \"objects\", \"objects\", \"objects\", \"objects\", \"occlusion\", \"occlusion\", \"occlusion\", \"ocsvm\", \"ogwild\", \"olfactory\", \"online\", \"online\", \"online\", \"online\", \"online\", \"oost\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"orthonormal\", \"orthonormal\", \"orthonormal\", \"orthonormal\", \"output\", \"output\", \"output\", \"output\", \"output\", \"pairwise\", \"pairwise\", \"pairwise\", \"pairwise\", \"pairwise\", \"partition\", \"partition\", \"partition\", \"partition\", \"partition\", \"patch\", \"patch\", \"patch\", \"patch\", \"patches\", \"patches\", \"patches\", \"patterns\", \"patterns\", \"patterns\", \"patterns\", \"patterns\", \"payoff\", \"payoff\", \"payoff\", \"pca\", \"pca\", \"pca\", \"pca\", \"pcfg\", \"pedestrian\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"phoneme\", \"phoneme\", \"phoneme\", \"phonetic\", \"pixel\", \"pixel\", \"pixel\", \"pixel\", \"pixel\", \"pixelcnn\", \"pixels\", \"pixels\", \"pixels\", \"pixels\", \"pixels\", \"planning\", \"planning\", \"planning\", \"planning\", \"plasticity\", \"player\", \"player\", \"player\", \"player\", \"players\", \"players\", \"players\", \"players\", \"players\", \"policies\", \"policies\", \"policies\", \"policies\", \"policy\", \"policy\", \"policy\", \"pose\", \"pose\", \"pose\", \"pose\", \"pose\", \"posterior\", \"posterior\", \"posterior\", \"posterior\", \"postsynaptic\", \"presynaptic\", \"privacy\", \"privacy\", \"privacy\", \"privacy\", \"private\", \"private\", \"private\", \"private\", \"private\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"proof\", \"proof\", \"proof\", \"proof\", \"proof\", \"prox\", \"prox\", \"proximal\", \"proximal\", \"proximal\", \"proximal\", \"proximal\", \"pulse\", \"pyramid\", \"pyramid\", \"pyramid\", \"pyramid\", \"query\", \"query\", \"query\", \"query\", \"quic\", \"rademacher\", \"rademacher\", \"random\", \"random\", \"random\", \"random\", \"random\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"ranking\", \"ranking\", \"ranking\", \"ranking\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rcnn\", \"rd\", \"rd\", \"rd\", \"rd\", \"rd\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"reflectance\", \"reflectance\", \"regret\", \"regret\", \"regret\", \"regularization\", \"regularization\", \"regularization\", \"regularization\", \"regularization\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representations\", \"representations\", \"representations\", \"representations\", \"representations\", \"response\", \"response\", \"response\", \"response\", \"response\", \"responses\", \"responses\", \"responses\", \"responses\", \"responses\", \"results\", \"results\", \"results\", \"results\", \"results\", \"reward\", \"reward\", \"reward\", \"rewards\", \"rewards\", \"rewards\", \"rezende\", \"rip\", \"rip\", \"rip\", \"rmsprop\", \"rn\", \"rn\", \"rn\", \"rn\", \"rn\", \"rollout\", \"rollouts\", \"rpca\", \"sag\", \"sag\", \"saga\", \"saliency\", \"saliency\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"schatten\", \"sdca\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentations\", \"segmentations\", \"seller\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"sensory\", \"sensory\", \"sensory\", \"sensory\", \"sentence\", \"sentence\", \"sentence\", \"sentences\", \"sentences\", \"sentences\", \"set\", \"set\", \"set\", \"set\", \"set\", \"sghmc\", \"sgld\", \"shalev\", \"shalev\", \"shalev\", \"shown\", \"shown\", \"shown\", \"shown\", \"shown\", \"shwartz\", \"shwartz\", \"shwartz\", \"sift\", \"sift\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"signals\", \"signals\", \"signals\", \"signals\", \"signals\", \"singular\", \"singular\", \"singular\", \"singular\", \"singular\", \"slds\", \"spammer\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparsity\", \"sparsity\", \"sparsity\", \"sparsity\", \"sparsity\", \"speaker\", \"speaker\", \"speaker\", \"speaker\", \"speaker\", \"speakers\", \"speakers\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech\", \"spike\", \"spike\", \"spike\", \"spike\", \"spikes\", \"spikes\", \"spikes\", \"spiking\", \"st\", \"st\", \"st\", \"st\", \"st\", \"state\", \"state\", \"state\", \"state\", \"state\", \"stdp\", \"stimuli\", \"stimuli\", \"stimulus\", \"stimulus\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"submodular\", \"submodular\", \"submodular\", \"submodularity\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"sup\", \"sup\", \"sup\", \"sup\", \"supermodular\", \"svd\", \"svd\", \"svd\", \"svd\", \"svhn\", \"svp\", \"svrg\", \"synapse\", \"synapses\", \"synaptic\", \"teboulle\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"tensorflow\", \"texture\", \"texture\", \"texture\", \"texture\", \"textures\", \"textures\", \"textures\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"time\", \"time\", \"time\", \"time\", \"time\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"torralba\", \"torralba\", \"trained\", \"trained\", \"trained\", \"trained\", \"trained\", \"training\", \"training\", \"training\", \"training\", \"training\", \"transistor\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"trees\", \"trees\", \"trees\", \"trees\", \"trees\", \"treewidth\", \"tropp\", \"trw\", \"trw\", \"ucb\", \"ucb\", \"ucb\", \"ucb\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"units\", \"units\", \"units\", \"units\", \"units\", \"use\", \"use\", \"use\", \"use\", \"use\", \"used\", \"used\", \"used\", \"used\", \"used\", \"using\", \"using\", \"using\", \"using\", \"using\", \"vae\", \"value\", \"value\", \"value\", \"value\", \"value\", \"variables\", \"variables\", \"variables\", \"variables\", \"variables\", \"verb\", \"verb\", \"verbs\", \"vershynin\", \"vertex\", \"vertex\", \"vertex\", \"vertex\", \"vertices\", \"vertices\", \"vertices\", \"vertices\", \"video\", \"video\", \"video\", \"video\", \"video\", \"vision\", \"vision\", \"vision\", \"vision\", \"vision\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"vlsi\", \"vlsi\", \"voc\", \"voiced\", \"voltage\", \"voltages\", \"vowels\", \"vqa\", \"waibel\", \"weights\", \"weights\", \"weights\", \"weights\", \"weights\", \"wgan\", \"wierstra\", \"woodruff\", \"word\", \"word\", \"word\", \"word\", \"word\", \"wordnet\", \"words\", \"words\", \"words\", \"words\", \"words\", \"xi\", \"xi\", \"xi\", \"xi\", \"xi\", \"xj\", \"xj\", \"xj\", \"xj\", \"xj\", \"xt\", \"xt\", \"xt\", \"xt\", \"xt\", \"yeast\", \"yeast\", \"ylx\", \"ylx\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 5, 4, 2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el690817289954083368533809608\", ldavis_el690817289954083368533809608_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el690817289954083368533809608\", ldavis_el690817289954083368533809608_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el690817289954083368533809608\", ldavis_el690817289954083368533809608_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2      0.053008 -0.004342       1        1  30.795392\n",
       "4      0.119436 -0.068006       2        1  20.270803\n",
       "3     -0.071196  0.047023       3        1  19.024489\n",
       "1     -0.132322 -0.066790       4        1  16.003177\n",
       "0      0.031075  0.092116       5        1  13.906140, topic_info=           Term          Freq         Total Category  logprob  loglift\n",
       "162992    image  29412.000000  29412.000000  Default  30.0000  30.0000\n",
       "227697   policy  15330.000000  15330.000000  Default  29.0000  29.0000\n",
       "163063   images  18964.000000  18964.000000  Default  28.0000  28.0000\n",
       "207886  network  43823.000000  43823.000000  Default  27.0000  27.0000\n",
       "194320   matrix  42482.000000  42482.000000  Default  26.0000  26.0000\n",
       "...         ...           ...           ...      ...      ...      ...\n",
       "11858        10   6743.552005  64195.966892   Topic5  -5.9104  -0.2805\n",
       "253177      set   6745.378676  73670.906165   Topic5  -5.9101  -0.4179\n",
       "231211  problem   6492.531516  51804.753922   Topic5  -5.9483  -0.1040\n",
       "90749     based   6216.293905  42458.809870   Topic5  -5.9918   0.0515\n",
       "207886  network   6082.751485  43823.869032   Topic5  -6.0135  -0.0019\n",
       "\n",
       "[531 rows x 6 columns], token_table=        Topic      Freq   Term\n",
       "term                          \n",
       "11858       1  0.366799     10\n",
       "11858       2  0.255250     10\n",
       "11858       3  0.131768     10\n",
       "11858       4  0.141115     10\n",
       "11858       5  0.105053     10\n",
       "...       ...       ...    ...\n",
       "296494      5  0.462325     xt\n",
       "297937      1  0.992799  yeast\n",
       "297937      3  0.003940  yeast\n",
       "298808      1  0.994790    ylx\n",
       "298808      3  0.003540    ylx\n",
       "\n",
       "[1404 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 5, 4, 2, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "from pyLDAvis import lda_model as sklearn_lda\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = sklearn_lda.prepare(lda, count_data, count_vectorizer)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Maarten Grootendorst's work on topic modeling with BERT:\n",
    "\n",
    "https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6\n",
    "\n",
    "https://towardsdatascience.com/interactive-topic-modeling-with-bertopic-1ea55e7d73d8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
